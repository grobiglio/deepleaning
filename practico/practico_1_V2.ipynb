{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad92109e",
   "metadata": {},
   "source": [
    "# Práctico 1\n",
    "\n",
    "[Enunciado](https://github.com/DiploDatos/AprendizajeProfundo/blob/master/Practico.md) del trabajo práctico.\n",
    "\n",
    "**Implementación de red neuronal [Perceptrón Multicapa](https://en.wikipedia.org/wiki/Multilayer_perceptron) (MLP).**\n",
    "\n",
    "## Integrantes\n",
    "- Mauricio Caggia\n",
    "- Luciano Monforte\n",
    "- Gustavo Venchiarutti\n",
    "- Guillermo Robiglio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d74bd8",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d08584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import mlflow\n",
    "import pandas as pd\n",
    "import tempfile\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from gensim import corpora\n",
    "from gensim.parsing import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import average_precision_score\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from tqdm.notebook import tqdm, trange"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e78fb0",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5a343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHIVO_SET_DE_ENTRENAMIENTO = './data/meli-challenge-2019/spanish.train.jsonl.gz'\n",
    "ARCHIVO_SET_DE_PRUEBA = './data/meli-challenge-2019/spanish.test.jsonl.gz'\n",
    "ARCHIVO_SET_DE_VALIDACION = './data/meli-challenge-2019/spanish.validation.jsonl.gz'\n",
    "ARCHIVO_TOKENS = './data/meli-challenge-2019/spanish_token_to_index.json.gz'\n",
    "# ARCHIVO_DE_EMBEDDINGS = './data/SBW-vectors-300-min5.txt.bz2'\n",
    "ARCHIVO_DE_EMBEDDINGS = '../data/glove.6B.50d.txt.gz'\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb3a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHIVO_SET_DE_ENTRENAMIENTO_1 = './data/training_set1.csv'\n",
    "ARCHIVO_SET_DE_ENTRENAMIENTO_2 = './data/training_set2.csv'\n",
    "ARCHIVO_SET_DE_PRUEBA = './data/test_set.csv'\n",
    "ARCHIVO_SET_DE_VALIDACION = './data/validation_set.csv'\n",
    "# ARCHIVO_DE_EMBEDDINGS = './data/SBW-vectors-300-min5.txt.bz2'\n",
    "ARCHIVO_DE_EMBEDDINGS = '../data/glove.6B.50d.txt.gz'\n",
    "EPOCHS = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd7676",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Esta carga de datos se realiza con el fin de explorar los mismos. Otra carga de datos tendrá lugar al comento de construir el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file_paths = [ARCHIVO_SET_DE_ENTRENAMIENTO,\n",
    "              ARCHIVO_SET_DE_PRUEBA,\n",
    "              ARCHIVO_SET_DE_VALIDACION]\n",
    "i = 1\n",
    "df = pd.read_json(path_or_buf=file_paths[i], lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93f9d6c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file_paths = [ARCHIVO_SET_DE_ENTRENAMIENTO_1,\n",
    "              ARCHIVO_SET_DE_ENTRENAMIENTO_2,\n",
    "              ARCHIVO_SET_DE_PRUEBA,\n",
    "              ARCHIVO_SET_DE_VALIDACION]\n",
    "i = 0\n",
    "df = pd.read_csv(file_paths[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1304190e",
   "metadata": {},
   "source": [
    "## Análisis y visualización de los datos\n",
    "\n",
    "El **set de entrenamiento** original tiene 4895280 registros con valores no nulos y 10 columnas. Las columnas de dicho dataset son:\n",
    "- **language**: El idioma del dataset (españor o portugués). En el trabajo práctico utilizaremos solamente el dataset es español.\n",
    "- **label_quality**: Calidad de la etiqueta (confiable o no confiable). Se dispone de 4508043 registros no confiables y 387237 registros confiables.\n",
    "- **title**: El título que se asignó al producto. **Esta información es la que se utilizará para armar el dataser de entrenamiento.**\n",
    "- **category**: La categoría que se asignó al producto. **Este es el target**.\n",
    "- **split**: El tipo de dataset. _train_ para el set de entrenamiento.\n",
    "- **tokenized_title**: El título tokenizado. Esto significa que los datos fueron preprocesados.\n",
    "- **data**: El número asignado a cada palabra del título tokenizado.\n",
    "- **target**: El número que corresponde a cada categoría.\n",
    "- **n_labels**: Cantidad de etiquetas numéricas correspondientes a las distintas categorías. 632 etiquetas (0 a 631) para el caso del set de entrenamiento.\n",
    "- **size**: La cantidad de registros. 4895280 registros para el caso del set de entrenamiento.\n",
    "\n",
    "El **set de prueba** original tiene 63680 registros con valores no nulos y 10 columnas. Las columnas de dicho dataset son:\n",
    "- **language**: El idioma del dataset (españor o portugués). En el trabajo práctico utilizaremos solamente el dataset es español.\n",
    "- **label_quality**: Calidad de la etiqueta (confiable o no confiable). Todas las etiquetas de este dataset son confiables.\n",
    "- **title**: El título que se asignó al producto.\n",
    "- **category**: La categoría que se asignó al producto.\n",
    "- **split**: El tipo de dataset. _test_ para el set de prueba.\n",
    "- **tokenized_title**: El título tokenizado. Esto significa que los datos fueron preprocesados.\n",
    "- **data**: El número asignado a cada palabra del título tokenizado.\n",
    "- **target**: El número que corresponde a cada categoría.\n",
    "- **n_labels**: Cantidad de etiquetas numéricas correspondientes a las distintas categorías. 632 etiquetas (0 a 631) para el caso del set de prueba.\n",
    "- **size**: La cantidad de registros. 63680 registros para el caso del set de prueba.\n",
    "\n",
    "El **set de validación** original tiene 1223820 registros con valores no nulos y 10 columnas. Las columnas de dicho dataset son:\n",
    "- **language**: El idioma del dataset (españor o portugués). En el trabajo práctico utilizaremos solamente el dataset es español.\n",
    "- **label_quality**: Calidad de la etiqueta (confiable o no confiable). Se dispone de 1127189 registros no confiables y 96631 registros confiables.\n",
    "- **title**: El título que se asignó al producto.\n",
    "- **category**: La categoría que se asignó al producto.\n",
    "- **split**: El tipo de dataset. _validation_ para el set de prueba.\n",
    "- **tokenized_title**: El título tokenizado. Esto significa que los datos fueron preprocesados.\n",
    "- **data**: El número asignado a cada palabra del título tokenizado.\n",
    "- **target**: El número que corresponde a cada categoría.\n",
    "- **n_labels**: Cantidad de etiquetas numéricas correspondientes a las distintas categorías. 632 etiquetas (0 a 631) para el caso del set de validación.\n",
    "- **size**: La cantidad de registros. 1223820 registros para el caso del set de validación.\n",
    "\n",
    "El archivo **spanish_token_to_index** tiene las 50002 correspondencias que existen entre las palabras tokenizadas del título y las etiquetas numéricas bajo la columna data en los sets de entrenamiento, prueba y validación. No se utilizará este tokenizador, en lugar de ello se utilizará ...\n",
    "\n",
    "**En este trabajo práctico se utiliza:**\n",
    "- El **set de entrenamiento** para entrenar el modelo\n",
    "- El **set de validación** para evaluar el modelo y ajustar hiperparámetros\n",
    "- El **set de prueba** para mostrar el mejor modelo obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c08a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a0f27",
   "metadata": {},
   "source": [
    "Para el presente trabajo práctico solamente interesan las columnas **title** y **category**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e2a0a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['language', 'label_quality', 'split', 'tokenized_title', 'data', 'target', 'n_labels', 'size'],\n",
    "        inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b0f8da",
   "metadata": {},
   "source": [
    "### Etiquetar el target.\n",
    "\n",
    "A cada una de las 632 categorías del target se le asigna un valor entero entre 0 y 631. La relación entre la categoría u su etiqueta queda almacenada en un dataframe de Pandas llamado `df_categories`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e079aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df.category.unique()\n",
    "sorted_categories = np.sort(categories)\n",
    "df_categories = pd.DataFrame(sorted_categories, columns=['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29920e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories['cat_tag'] = pd.DataFrame(list(range(df_categories.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c279da02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories.set_index('categories', inplace=True)\n",
    "df_categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1d327",
   "metadata": {},
   "source": [
    "## Construcción del Dataset\n",
    "\n",
    "El dataset se construye a partir de un dataframe de Pandas que debe tener al menos dos columnas:\n",
    "- **title**\n",
    "- **category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba04cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeLiChallengeDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        item = {\n",
    "            \"data\": self.df.iloc[item][\"title\"],\n",
    "            \"target\": self.df.iloc[item][\"category\"]\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            item = self.transform(item)\n",
    "        \n",
    "        return item"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e833f",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los datos\n",
    "\n",
    "El preprocesamiento de texto tiene dos propósitos:\n",
    "- Tokenizar los títulos (datos) de modo que se quiten los signos de puntuación y palabras cortas como preposiciones y conjunciones (stopwords), todas las palabras queden en minúsculas, se separen en listas de palabras, etc.\n",
    "- Transformar las categorías en etiquetas numéricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d206bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RawDataProcessor:\n",
    "    def __init__(self, dataset, ignore_header=True, vocab_size=50000):\n",
    "        self.filters = [lambda s: s.lower(),\n",
    "                        preprocessing.strip_tags,\n",
    "                        preprocessing.strip_punctuation,\n",
    "                        preprocessing.strip_multiple_whitespaces,\n",
    "                        preprocessing.strip_numeric,\n",
    "                        preprocessing.remove_stopwords,\n",
    "                        preprocessing.strip_short]\n",
    "        \n",
    "        # Esta clase encapsula el mapeo entre las palabras normalizadas y sus correspondientes indices \n",
    "        # https://radimrehurek.com/gensim/corpora/dictionary.html\n",
    "        self.dictionary = corpora.Dictionary(\n",
    "            dataset[\"title\"].map(self._preprocess_string).tolist()\n",
    "        )\n",
    "        \n",
    "        # Filter the dictionary with extremos words\n",
    "        # https://tedboy.github.io/nlps/generated/generated/gensim.corpora.Dictionary.filter_extremes.html?highlight=filter_extrem\n",
    "        self.dictionary.filter_extremes(no_below=2, no_above=1, keep_n=vocab_size)\n",
    "        \n",
    "        # Asigna nuevos índices a todas las palabras\n",
    "        # https://tedboy.github.io/nlps/generated/generated/gensim.corpora.Dictionary.compactify.html\n",
    "        # https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.compactify\n",
    "        self.dictionary.compactify()\n",
    "        \n",
    "        # Se agregan tokens especiales\n",
    "        self.dictionary.patch_with_special_tokens({\"[PAD]\": 0,\n",
    "                                                   \"[UNK]\": 1})\n",
    "        \n",
    "        # Conversión de categorías a etiquetas\n",
    "        self.idx_to_target = sorted(dataset[\"category\"].unique())\n",
    "        self.target_to_idx = {t: i for i, t in enumerate(self.idx_to_target)}\n",
    "\n",
    "\n",
    "    def _preprocess_string(self, string):\n",
    "        # Procesamiento de los títulos mediante la aplicación de una lista de filtros\n",
    "        # Parámetro: str -> El título sin procesar\n",
    "        # Salida: list -> Lista de strings\n",
    "        # https://radimrehurek.com/gensim/parsing/preprocessing.html#gensim.parsing.preprocessing.preprocess_string\n",
    "        return preprocessing.preprocess_string(string, filters=self.filters)\n",
    "\n",
    "    def _sentence_to_indices(self, sentence):\n",
    "        # Convierte una lista de palabras en una lista de índices\n",
    "        # Parámetro: list -> Lista de palabras\n",
    "        # Salida: list -> Lista de enteros (índices) en el mismo orden que las palabras\n",
    "        # https://radimrehurek.com/gensim/corpora/dictionary.html#gensim.corpora.dictionary.Dictionary.doc2idx\n",
    "        return self.dictionary.doc2idx(sentence, unknown_word_index=1)\n",
    "    \n",
    "    def encode_data(self, data):\n",
    "        # Convierte un string en una lista de índices\n",
    "        return self._sentence_to_indices(self._preprocess_string(data))\n",
    "    \n",
    "    def encode_target(self, target):\n",
    "        # Convierte las categorías a etiquetas\n",
    "        return self.target_to_idx[target]\n",
    "    \n",
    "    def __call__(self, item):\n",
    "        if isinstance(item[\"data\"], str):\n",
    "            data = self.encode_data(item[\"data\"])\n",
    "        else:\n",
    "            data = [self.encode_data(d) for d in item[\"data\"]]\n",
    "        \n",
    "        if isinstance(item[\"target\"], str):\n",
    "            target = self.encode_target(item[\"target\"])\n",
    "        else:\n",
    "            target = [self.encode_target(t) for t in item[\"target\"]]\n",
    "        \n",
    "        return {\n",
    "            \"data\": data,\n",
    "            \"target\": target\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c66071",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PadSequences:\n",
    "    def __init__(self, pad_value=0, max_length=None, min_length=1):\n",
    "        assert max_length is None or min_length <= max_length\n",
    "        self.pad_value = pad_value\n",
    "        self.max_length = max_length\n",
    "        self.min_length = min_length\n",
    "\n",
    "    def __call__(self, items):\n",
    "        data, target = list(zip(*[(item[\"data\"], item[\"target\"]) for item in items]))\n",
    "        seq_lengths = [len(d) for d in data]\n",
    "\n",
    "        if self.max_length:\n",
    "            max_length = self.max_length\n",
    "            seq_lengths = [min(self.max_length, l) for l in seq_lengths]\n",
    "        else:\n",
    "            max_length = max(self.min_length, max(seq_lengths))\n",
    "\n",
    "        data = [d[:l] + [self.pad_value] * (max_length - l)\n",
    "                for d, l in zip(data, seq_lengths)]\n",
    "            \n",
    "        return {\n",
    "            \"data\": torch.LongTensor(data),\n",
    "            \"target\": torch.FloatTensor(target)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "124b5563",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = RawDataProcessor(df)\n",
    "dataset = MeLiChallengeDataset(df, transform=processor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a804f035",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 1000\n",
    "print(f\"El dataset tiene {len(dataset)} elementos.\")\n",
    "print(f\"Elemento #{i}:\\n\\tData: {dataset[i]['data']}\\n\\tTarget: {dataset[i]['target']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720625c",
   "metadata": {},
   "source": [
    "## Carga del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e91fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pad_sequences = PadSequences()\n",
    "train_loader = DataLoader(dataset,\n",
    "                          batch_size=100,\n",
    "                          shuffle=True,\n",
    "                          collate_fn=pad_sequences,\n",
    "                          drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f7f30",
   "metadata": {},
   "source": [
    "## Construcción del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fdf2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeLiChallengeClassifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 pretrained_embeddings_path, \n",
    "                 dictionary,\n",
    "                 vector_size,\n",
    "                 freeze_embedings):\n",
    "        super().__init__()\n",
    "        embeddings_matrix = torch.randn(len(dictionary), vector_size)\n",
    "        embeddings_matrix[0] = torch.zeros(vector_size)\n",
    "        with gzip.open(pretrained_embeddings_path, \"rt\") as fh:\n",
    "            for line in fh:\n",
    "                word, vector = line.strip().split(None, 1)\n",
    "                if word in dictionary.token2id:\n",
    "                    embeddings_matrix[dictionary.token2id[word]] =\\\n",
    "                        torch.FloatTensor([float(n) for n in vector.split()])\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n",
    "                                                       freeze=freeze_embedings,\n",
    "                                                       padding_idx=0)\n",
    "        self.hidden1 = nn.Linear(vector_size, 128)\n",
    "        self.hidden2 = nn.Linear(128, 128)\n",
    "        self.output = nn.Linear(128, 632)\n",
    "        self.vector_size = vector_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = torch.mean(x, dim=1)\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274fe854",
   "metadata": {},
   "source": [
    "## Algoritmo de Optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a15de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MeLiChallengeClassifier(ARCHIVO_DE_EMBEDDINGS, processor.dictionary, 50, True)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7772d8",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dfe282f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9777a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for epoch in range(EPOCHS):  # Recorre el dataset multiples veces\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for data in train_loader:\n",
    "        inputs = data['data'].to(device)\n",
    "        labels = data['target'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = loss_function(outputs, labels.squeeze().long())\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378dee4",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e169eaaa",
   "metadata": {},
   "source": [
    "## Guardado de los parámetros del modelo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
