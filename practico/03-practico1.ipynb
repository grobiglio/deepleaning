{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad92109e",
   "metadata": {},
   "source": [
    "# Pr√°ctico 1 - Parte 3 de 3\n",
    "\n",
    "[Enunciado](https://github.com/DiploDatos/AprendizajeProfundo/blob/master/Practico.md) del trabajo pr√°ctico.\n",
    "\n",
    "**Implementaci√≥n de red neuronal [Perceptr√≥n Multicapa](https://en.wikipedia.org/wiki/Multilayer_perceptron) (MLP).**\n",
    "\n",
    "## Integrantes\n",
    "- Mauricio Caggia\n",
    "- Luciano Monforte\n",
    "- Gustavo Venchiarutti\n",
    "- Guillermo Robiglio\n",
    "\n",
    "En esta tercera parte se arman los datasets, los dataloaders y se entrena y prueba el modelo.\n",
    "\n",
    "## ‚ö† IMPORTANTE ‚ö†\n",
    "\n",
    "Por favor leer el archivo [Practico_1.md](https://github.com/grobiglio/deepleaning/blob/master/practico/Practico_1.md#deep-learning---trabajo-pr%C3%A1ctico-1) que se encuentra en el repositorio donde se puso este trabajo pr√°ctico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d74bd8",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d08584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from gensim import corpora\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from practico1_modulo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e78fb0",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb3a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd7676",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Carga de datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c88543",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.load('./data/X_train.pt')\n",
    "y_train = torch.load('./data/y_train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c4ec4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000, 17])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducci√≥n del dataset de entrenamiento es temporal\n",
    "# Cuando compruebe que funciona se eliminar√° esta celda.\n",
    "X_train = X_train[:1000000]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2005ef17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducci√≥n del dataset de entrenamiento es temporal\n",
    "# Cuando compruebe que funciona se eliminar√° esta celda.\n",
    "y_train = y_train[:1000000]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599bcadc",
   "metadata": {},
   "source": [
    "Carga de datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6081c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.load('./data/X_test.pt')\n",
    "y_test = torch.load('./data/y_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc46469e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500000, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducci√≥n del dataset de prueba es temporal.\n",
    "# Cuando compruebe que funciona se eliminar√° esta celda.\n",
    "X_test = X_test[:500000]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb67b68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducci√≥n del dataset de prueba es temporal.\n",
    "# Cuando compruebe que funciona se eliminar√° esta celda.\n",
    "y_test = y_test[:500000]\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd06aa0",
   "metadata": {},
   "source": [
    "## Embedding de t√≠tulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80989d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding\n",
    "embeddings_matrix = torch.load('./data/embeddings_matrix.pt')\n",
    "embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n",
    "                                          padding_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1d327",
   "metadata": {},
   "source": [
    "## Construcci√≥n del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "230d33c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db886f672d6430681885a7c5cdfecf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorrida exitosa de 10000 batches de entrenamiento.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71fc60d7f874c83bc3069acc7df43e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorrida exitosa de 5000 batches de prueba.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MeLiChallengeDataset(X_train, y_train)\n",
    "test_dataset = MeLiChallengeDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          drop_last=False)\n",
    "i = 0\n",
    "for data in tqdm(train_loader):\n",
    "    i += 1\n",
    "print(f'Recorrida exitosa de {i} batches de entrenamiento.')\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         drop_last=False)\n",
    "i = 0\n",
    "for data in tqdm(test_loader):\n",
    "    i += 1\n",
    "print(f'Recorrida exitosa de {i} batches de prueba.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f7f30",
   "metadata": {},
   "source": [
    "## Construcci√≥n del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a636a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = MeLiChallengeClassifier(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274fe854",
   "metadata": {},
   "source": [
    "## Algoritmo de Optimizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65a15de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(modelo.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7772d8",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dfe282f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MeLiChallengeClassifier(\n",
       "  (embeddings): Embedding(50002, 300, padding_idx=0)\n",
       "  (hidden1): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (hidden2): Linear(in_features=300, out_features=500, bias=True)\n",
       "  (output): Linear(in_features=500, out_features=632, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Utilizando {device}')\n",
    "modelo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37130256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    '''Entrenamiento de una red neuronal.\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    - dataloader: Iterador (objeto) de Pytorch construido en base al dataset basado en la clase MeLiChallengeDataset.\n",
    "    - model: Modelo (objeto) basado en la clase MeLiChallengeClassifier.\n",
    "    - loss_fn: Funci√≥n de costo.\n",
    "    - optimizer: Optimizador.\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    running_loss: Lista con los valores de la funci√≥n de costo minimizados.\n",
    "    \n",
    "    '''\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    running_loss = []\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        X, y = data['data'].to(device), data['target'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # pred: Dimensi√≥n 100 x 632\n",
    "        # y: Dimensi√≥n 100\n",
    "        # Por eso esto no funciona üò° ¬øC√≥mo se soluciona? üò°\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss.append(loss.item())\n",
    "        \n",
    "        if batch % 1000 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378dee4",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93bbbb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    '''Evaluaci√≥n de una red neuronal.\n",
    "    \n",
    "    Par√°metros:\n",
    "    -----------\n",
    "    - dataloader: Iterador (objeto) de Pytorch construido en base al dataset basado en la clase MeLiChallengeDataset.\n",
    "    - model: Modelo (objeto) basado en la clase MeLiChallengeClassifier.\n",
    "    - loss_fn: Funci√≥n de costo.\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    - running_loss: Lista con los valores de la funci√≥n de costo minimizados.\n",
    "    - targets: Lista con los valores verdaderos del objetivo.\n",
    "    - predictions: Lista con los valores predichos.\n",
    "    ‚ö† ATENCI√ìN ‚ö† Aqu√≠ hay un problema porque los targets son valores enteros y\n",
    "    las predicciones son decimales. No se pueden comparar para obtener un accuracy.\n",
    "    '''\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    running_loss = []\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            X, y = data['data'].to(device), data['target'].to(device)\n",
    "            pred = model(X)\n",
    "            y_true = y # Dimensi√≥n 100\n",
    "            y_pred = pred # Dimensi√≥n 100 x 632\n",
    "        try:\n",
    "            accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "            print(f\"Test Error: \\n Accuracy: {accuracy:>0.1f}%\")\n",
    "        except:\n",
    "            print('No es posible calcular el accuracy porque no coincide \\\n",
    "dimensi√≥n del valor predicho con la dimensi√≥n del valor verdadero.')\n",
    "        running_loss.append(loss_fn(pred, y))\n",
    "        targets.extend(y.cpu().detach().numpy())\n",
    "        predictions.extend(pred.cpu().squeeze().detach().numpy())\n",
    "                            \n",
    "    return running_loss, targets, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be87f5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 6.451149  [    0/1000000]\n",
      "loss: 6.448824  [100000/1000000]\n",
      "loss: 6.448419  [200000/1000000]\n",
      "loss: 6.447014  [300000/1000000]\n",
      "loss: 6.446904  [400000/1000000]\n",
      "loss: 6.446173  [500000/1000000]\n",
      "loss: 6.446985  [600000/1000000]\n",
      "loss: 6.444613  [700000/1000000]\n",
      "loss: 6.445238  [800000/1000000]\n",
      "loss: 6.446004  [900000/1000000]\n",
      "No es posible calcular el accuracy porque no coincide dimensi√≥n del valor predicho con la dimensi√≥n del valor verdadero.\n",
      "!Listo!\n"
     ]
    }
   ],
   "source": [
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    _ = train(train_loader, modelo, loss_function, optimizer)\n",
    "    _, _, _ = test(test_loader, modelo, loss_function)\n",
    "print(\"!Listo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccefb1c9",
   "metadata": {},
   "source": [
    "## ¬øPor qu√© sospechamos que no funciona?\n",
    "\n",
    "La red neuronal tiene como salida un vector de 632 componentes el cual es comparado con un solo componente, la etiqueta asocada a la clasificaci√≥n del t√≠tulo. Entiendemos que all√≠ hay una incompatibilidad que el c√≥digo acepta (no da error) pero que evidentemente no permite que la red aprenda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da0c4ca",
   "metadata": {},
   "source": [
    "## Optimizaci√≥n de hiperpar√°metros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd695a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/08 23:06:32 INFO mlflow.tracking.fluent: Experiment with name 'practico_1' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 6.448898  [    0/1000000]\n",
      "loss: 6.447157  [100000/1000000]\n",
      "loss: 6.448918  [200000/1000000]\n",
      "loss: 6.447146  [300000/1000000]\n",
      "loss: 6.448543  [400000/1000000]\n",
      "loss: 6.449569  [500000/1000000]\n",
      "loss: 6.448979  [600000/1000000]\n",
      "loss: 6.448914  [700000/1000000]\n",
      "loss: 6.447817  [800000/1000000]\n",
      "loss: 6.449285  [900000/1000000]\n",
      "No es posible calcular el accuracy porque no coincide dimensi√≥n del valor predicho con la dimensi√≥n del valor verdadero.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e060ccd244b44c3a78f4a0784a965b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"practico_1\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_name\", \"mlp\")\n",
    "    mlflow.log_params({\n",
    "        \"embedding_size\": 300,\n",
    "        \"hidden1_size\": 128,\n",
    "        \"hidden2_size\": 128\n",
    "    })\n",
    "    modelo = MeLiChallengeClassifier(embeddings)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(modelo.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    modelo.to(device)\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        # Entrenamiento del modelo\n",
    "        running_loss = train(train_loader, modelo, loss_function, optimizer)\n",
    "        '''\n",
    "        modelo.train()\n",
    "        running_loss = []\n",
    "        for idx, batch in enumerate(tqdm(train_loader)):\n",
    "            optimizer.zero_grad()\n",
    "            output = modelo(batch[\"data\"])\n",
    "            loss_value = loss(output, batch[\"target\"])\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            running_loss.append(loss_value.item())\n",
    "        '''\n",
    "        mlflow.log_metric(\"train_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "        \n",
    "        # Evaluaci√≥n del modelo\n",
    "        running_loss, targets, predictions = test(test_loader, modelo, loss_function)\n",
    "        '''\n",
    "        modelo.eval()\n",
    "        running_loss = []\n",
    "        targets = []\n",
    "        predictions = []\n",
    "        for batch in tqdm(test_loader):\n",
    "            output = modelo(batch[\"data\"])\n",
    "            running_loss.append(loss(output, batch[\"target\"]).item())\n",
    "            targets.extend(batch[\"target\"].numpy())\n",
    "            predictions.extend(output.squeeze().detach().numpy())\n",
    "        '''\n",
    "        mlflow.log_metric(\"test_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "        try:\n",
    "            mlflow.log_metric(\"test_avp\", balanced_accuracy_score(targets, predictions), epoch)\n",
    "        except:\n",
    "            targets = [1, 0, 0] # Valor dummie para que no de error\n",
    "            predictions = [0, 1, 0] # Valor dummie para que no de error\n",
    "            # El problema es que targets son valores enteros y predictions decimales\n",
    "            mlflow.log_metric(\"test_avp\", balanced_accuracy_score(targets, predictions), epoch)\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        targets = []\n",
    "        predictions = []\n",
    "        for batch in tqdm(test_loader):\n",
    "            X = batch['data'].to(device)\n",
    "            output = modelo(X)\n",
    "            targets.extend(batch[\"target\"].numpy())\n",
    "            predictions.extend(output.cpu().squeeze().detach().numpy())\n",
    "        pd.DataFrame({\"prediction\": predictions, \"target\": targets}).to_csv(f\"{tmpdirname}/predictions.csv.gz\", index=False)\n",
    "        mlflow.log_artifact(f\"{tmpdirname}/predictions.csv.gz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
