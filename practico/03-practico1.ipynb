{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad92109e",
   "metadata": {},
   "source": [
    "# Práctico 1 - Parte 3 de 3\n",
    "\n",
    "[Enunciado](https://github.com/DiploDatos/AprendizajeProfundo/blob/master/Practico.md) del trabajo práctico.\n",
    "\n",
    "**Implementación de red neuronal [Perceptrón Multicapa](https://en.wikipedia.org/wiki/Multilayer_perceptron) (MLP).**\n",
    "\n",
    "## Integrantes\n",
    "- Mauricio Caggia\n",
    "- Luciano Monforte\n",
    "- Gustavo Venchiarutti\n",
    "- Guillermo Robiglio\n",
    "\n",
    "En esta tercera parte se arman los datasets, los dataloaders y se entrena y prueba el modelo.\n",
    "\n",
    "## ⚠ IMPORTANTE ⚠\n",
    "\n",
    "Por favor leer el archivo [Practico_1.md](https://github.com/grobiglio/deepleaning/blob/master/practico/Practico_1.md#deep-learning---trabajo-pr%C3%A1ctico-1) que se encuentra en el repositorio donde se puso este trabajo práctico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d74bd8",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d08584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from gensim import corpora\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from practico1_modulo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e78fb0",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb3a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd7676",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Carga de datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c88543",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.load('./data/X_train.pt')\n",
    "y_train = torch.load('./data/y_train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c4ec4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000, 17])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducción del dataset de entrenamiento es temporal\n",
    "# Cuando compruebe que funciona se eliminará esta celda.\n",
    "X_train = X_train[:1000000]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2005ef17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducción del dataset de entrenamiento es temporal\n",
    "# Cuando compruebe que funciona se eliminará esta celda.\n",
    "y_train = y_train[:1000000]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599bcadc",
   "metadata": {},
   "source": [
    "Carga de datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6081c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.load('./data/X_test.pt')\n",
    "y_test = torch.load('./data/y_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc46469e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500000, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducción del dataset de prueba es temporal.\n",
    "# Cuando compruebe que funciona se eliminará esta celda.\n",
    "X_test = X_test[:500000]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb67b68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducción del dataset de prueba es temporal.\n",
    "# Cuando compruebe que funciona se eliminará esta celda.\n",
    "y_test = y_test[:500000]\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd06aa0",
   "metadata": {},
   "source": [
    "## Embedding de títulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80989d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding\n",
    "embeddings_matrix = torch.load('./data/embeddings_matrix.pt')\n",
    "embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n",
    "                                          padding_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1d327",
   "metadata": {},
   "source": [
    "## Construcción del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "230d33c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9db886f672d6430681885a7c5cdfecf8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorrida exitosa de 10000 batches de entrenamiento.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a71fc60d7f874c83bc3069acc7df43e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorrida exitosa de 5000 batches de prueba.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MeLiChallengeDataset(X_train, y_train)\n",
    "test_dataset = MeLiChallengeDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          drop_last=False)\n",
    "i = 0\n",
    "for data in tqdm(train_loader):\n",
    "    i += 1\n",
    "print(f'Recorrida exitosa de {i} batches de entrenamiento.')\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         drop_last=False)\n",
    "i = 0\n",
    "for data in tqdm(test_loader):\n",
    "    i += 1\n",
    "print(f'Recorrida exitosa de {i} batches de prueba.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f7f30",
   "metadata": {},
   "source": [
    "## Construcción del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a636a42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = MeLiChallengeClassifier(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274fe854",
   "metadata": {},
   "source": [
    "## Algoritmo de Optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65a15de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(modelo.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7772d8",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4dfe282f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MeLiChallengeClassifier(\n",
       "  (embeddings): Embedding(50002, 300, padding_idx=0)\n",
       "  (hidden1): Linear(in_features=300, out_features=300, bias=True)\n",
       "  (hidden2): Linear(in_features=300, out_features=500, bias=True)\n",
       "  (output): Linear(in_features=500, out_features=632, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Utilizando {device}')\n",
    "modelo.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37130256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    '''Entrenamiento de una red neuronal.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    - dataloader: Iterador (objeto) de Pytorch construido en base al dataset basado en la clase MeLiChallengeDataset.\n",
    "    - model: Modelo (objeto) basado en la clase MeLiChallengeClassifier.\n",
    "    - loss_fn: Función de costo.\n",
    "    - optimizer: Optimizador.\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    running_loss: Lista con los valores de la función de costo minimizados.\n",
    "    \n",
    "    '''\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    running_loss = []\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        X, y = data['data'].to(device), data['target'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "        # pred: Dimensión 100 x 632\n",
    "        # y: Dimensión 100\n",
    "        # Por eso esto no funciona 😡 ¿Cómo se soluciona? 😡\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss.append(loss.item())\n",
    "        \n",
    "        if batch % 1000 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
    "            \n",
    "    return running_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378dee4",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "93bbbb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    '''Evaluación de una red neuronal.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    - dataloader: Iterador (objeto) de Pytorch construido en base al dataset basado en la clase MeLiChallengeDataset.\n",
    "    - model: Modelo (objeto) basado en la clase MeLiChallengeClassifier.\n",
    "    - loss_fn: Función de costo.\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    - running_loss: Lista con los valores de la función de costo minimizados.\n",
    "    - targets: Lista con los valores verdaderos del objetivo.\n",
    "    - predictions: Lista con los valores predichos.\n",
    "    ⚠ ATENCIÓN ⚠ Aquí hay un problema porque los targets son valores enteros y\n",
    "    las predicciones son decimales. No se pueden comparar para obtener un accuracy.\n",
    "    '''\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    running_loss = []\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            X, y = data['data'].to(device), data['target'].to(device)\n",
    "            pred = model(X)\n",
    "            y_true = y # Dimensión 100\n",
    "            y_pred = pred # Dimensión 100 x 632\n",
    "        try:\n",
    "            accuracy = balanced_accuracy_score(y_true, y_pred)\n",
    "            print(f\"Test Error: \\n Accuracy: {accuracy:>0.1f}%\")\n",
    "        except:\n",
    "            print('No es posible calcular el accuracy porque no coincide \\\n",
    "dimensión del valor predicho con la dimensión del valor verdadero.')\n",
    "        running_loss.append(loss_fn(pred, y))\n",
    "        targets.extend(y.cpu().detach().numpy())\n",
    "        predictions.extend(pred.cpu().squeeze().detach().numpy())\n",
    "                            \n",
    "    return running_loss, targets, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "be87f5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 6.451149  [    0/1000000]\n",
      "loss: 6.448824  [100000/1000000]\n",
      "loss: 6.448419  [200000/1000000]\n",
      "loss: 6.447014  [300000/1000000]\n",
      "loss: 6.446904  [400000/1000000]\n",
      "loss: 6.446173  [500000/1000000]\n",
      "loss: 6.446985  [600000/1000000]\n",
      "loss: 6.444613  [700000/1000000]\n",
      "loss: 6.445238  [800000/1000000]\n",
      "loss: 6.446004  [900000/1000000]\n",
      "No es posible calcular el accuracy porque no coincide dimensión del valor predicho con la dimensión del valor verdadero.\n",
      "!Listo!\n"
     ]
    }
   ],
   "source": [
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    _ = train(train_loader, modelo, loss_function, optimizer)\n",
    "    _, _, _ = test(test_loader, modelo, loss_function)\n",
    "print(\"!Listo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccefb1c9",
   "metadata": {},
   "source": [
    "## ¿Por qué sospechamos que no funciona?\n",
    "\n",
    "La red neuronal tiene como salida un vector de 632 componentes el cual es comparado con un solo componente, la etiqueta asocada a la clasificación del título. Entiendemos que allí hay una incompatibilidad que el código acepta (no da error) pero que evidentemente no permite que la red aprenda."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9da0c4ca",
   "metadata": {},
   "source": [
    "## Optimización de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fd695a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/11/08 23:06:32 INFO mlflow.tracking.fluent: Experiment with name 'practico_1' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 6.448898  [    0/1000000]\n",
      "loss: 6.447157  [100000/1000000]\n",
      "loss: 6.448918  [200000/1000000]\n",
      "loss: 6.447146  [300000/1000000]\n",
      "loss: 6.448543  [400000/1000000]\n",
      "loss: 6.449569  [500000/1000000]\n",
      "loss: 6.448979  [600000/1000000]\n",
      "loss: 6.448914  [700000/1000000]\n",
      "loss: 6.447817  [800000/1000000]\n",
      "loss: 6.449285  [900000/1000000]\n",
      "No es posible calcular el accuracy porque no coincide dimensión del valor predicho con la dimensión del valor verdadero.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e060ccd244b44c3a78f4a0784a965b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"practico_1\")\n",
    "\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_param(\"model_name\", \"mlp\")\n",
    "    mlflow.log_params({\n",
    "        \"embedding_size\": 300,\n",
    "        \"hidden1_size\": 128,\n",
    "        \"hidden2_size\": 128\n",
    "    })\n",
    "    modelo = MeLiChallengeClassifier(embeddings)\n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.SGD(modelo.parameters(), lr=0.001, weight_decay=1e-5)\n",
    "    modelo.to(device)\n",
    "    for epoch in range(EPOCHS):\n",
    "        print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "        # Entrenamiento del modelo\n",
    "        running_loss = train(train_loader, modelo, loss_function, optimizer)\n",
    "        '''\n",
    "        modelo.train()\n",
    "        running_loss = []\n",
    "        for idx, batch in enumerate(tqdm(train_loader)):\n",
    "            optimizer.zero_grad()\n",
    "            output = modelo(batch[\"data\"])\n",
    "            loss_value = loss(output, batch[\"target\"])\n",
    "            loss_value.backward()\n",
    "            optimizer.step()\n",
    "            running_loss.append(loss_value.item())\n",
    "        '''\n",
    "        mlflow.log_metric(\"train_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "        \n",
    "        # Evaluación del modelo\n",
    "        running_loss, targets, predictions = test(test_loader, modelo, loss_function)\n",
    "        '''\n",
    "        modelo.eval()\n",
    "        running_loss = []\n",
    "        targets = []\n",
    "        predictions = []\n",
    "        for batch in tqdm(test_loader):\n",
    "            output = modelo(batch[\"data\"])\n",
    "            running_loss.append(loss(output, batch[\"target\"]).item())\n",
    "            targets.extend(batch[\"target\"].numpy())\n",
    "            predictions.extend(output.squeeze().detach().numpy())\n",
    "        '''\n",
    "        mlflow.log_metric(\"test_loss\", sum(running_loss) / len(running_loss), epoch)\n",
    "        try:\n",
    "            mlflow.log_metric(\"test_avp\", balanced_accuracy_score(targets, predictions), epoch)\n",
    "        except:\n",
    "            targets = [1, 0, 0] # Valor dummie para que no de error\n",
    "            predictions = [0, 1, 0] # Valor dummie para que no de error\n",
    "            # El problema es que targets son valores enteros y predictions decimales\n",
    "            mlflow.log_metric(\"test_avp\", balanced_accuracy_score(targets, predictions), epoch)\n",
    "    \n",
    "    with tempfile.TemporaryDirectory() as tmpdirname:\n",
    "        targets = []\n",
    "        predictions = []\n",
    "        for batch in tqdm(test_loader):\n",
    "            X = batch['data'].to(device)\n",
    "            output = modelo(X)\n",
    "            targets.extend(batch[\"target\"].numpy())\n",
    "            predictions.extend(output.cpu().squeeze().detach().numpy())\n",
    "        pd.DataFrame({\"prediction\": predictions, \"target\": targets}).to_csv(f\"{tmpdirname}/predictions.csv.gz\", index=False)\n",
    "        mlflow.log_artifact(f\"{tmpdirname}/predictions.csv.gz\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
