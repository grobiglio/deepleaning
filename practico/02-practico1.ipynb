{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad92109e",
   "metadata": {},
   "source": [
    "# Práctico 1 - Parte 2 de 3\n",
    "\n",
    "[Enunciado](https://github.com/DiploDatos/AprendizajeProfundo/blob/master/Practico.md) del trabajo práctico.\n",
    "\n",
    "**Implementación de red neuronal [Perceptrón Multicapa](https://en.wikipedia.org/wiki/Multilayer_perceptron) (MLP).**\n",
    "\n",
    "## Integrantes\n",
    "- Mauricio Caggia\n",
    "- Luciano Monforte\n",
    "- Gustavo Venchiarutti\n",
    "- Guillermo Robiglio\n",
    "\n",
    "En esta segunda parte se preprocesan los datos y se los guarda para ser utilizados en la tercera parte, en la que se arma el dataset y se entrena y prueba el modelo.\n",
    "\n",
    "## ⚠ IMPORTANTE ⚠\n",
    "\n",
    "Por favor leer el archivo [Practico_1.md](https://github.com/grobiglio/deepleaning/blob/master/practico/Practico_1.md#deep-learning---trabajo-pr%C3%A1ctico-1) que se encuentra en el repositorio donde se puso este trabajo práctico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d74bd8",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d08584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from gensim import corpora\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from practico1_modulo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e78fb0",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb3a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHIVO_SET_DE_ENTRENAMIENTO = './data/training_set.csv'\n",
    "ARCHIVO_SET_DE_PRUEBA = './data/test_set.csv'\n",
    "ARCHIVO_SET_DE_VALIDACION = './data/validation_set.csv'\n",
    "ARCHIVO_DE_EMBEDDINGS = './data/SBW-vectors-300-min5.txt.bz2'\n",
    "ARCHIVO_DICCIONARIO = './data/diccionario.txt'\n",
    "EPOCHS = 5\n",
    "VOCAB_SIZE = 50000 # Cantidad de palabras en el diccionario\n",
    "MUESTRAS = 0 # Cantidad de muestras que se toman del set de entrenamiento\n",
    "             # Si se configura valor 0 (cero) se toman todas las muestras\n",
    "TOKENS_ESPECIALES = {'[relleno]': 0, '[desconocido]': 1}\n",
    "VALOR_DE_RELLENO = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd7676",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Carga de datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f9d6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados con éxito, a continuación una muestra de los datos.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Casita Muñecas Barbies Pintadas</td>\n",
       "      <td>DOLLHOUSES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neceser Cromado Holográfico</td>\n",
       "      <td>TOILETRY_BAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Funda Asiento A Medida D20 Chevrolet</td>\n",
       "      <td>CAR_SEAT_COVERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Embrague Ford Focus One 1.8 8v Td (90cv) Desde...</td>\n",
       "      <td>AUTOMOTIVE_CLUTCH_KITS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bateria Panasonic Dmwbcf10 Lumix Dmc-fx60n Dmc...</td>\n",
       "      <td>CAMERA_BATTERIES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                category\n",
       "0                    Casita Muñecas Barbies Pintadas              DOLLHOUSES\n",
       "1                       Neceser Cromado Holográfico            TOILETRY_BAGS\n",
       "2               Funda Asiento A Medida D20 Chevrolet         CAR_SEAT_COVERS\n",
       "3  Embrague Ford Focus One 1.8 8v Td (90cv) Desde...  AUTOMOTIVE_CLUTCH_KITS\n",
       "4  Bateria Panasonic Dmwbcf10 Lumix Dmc-fx60n Dmc...        CAMERA_BATTERIES"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entrenamiento = pd.read_csv(ARCHIVO_SET_DE_ENTRENAMIENTO)\n",
    "\n",
    "print('Datos cargados con éxito, a continuación una muestra de los datos.')\n",
    "df_entrenamiento.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599bcadc",
   "metadata": {},
   "source": [
    "Carga de datos de validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd6f4a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados con éxito, a continuación una muestra de los datos.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Metal Biela Dw10 Hdi 2.0</td>\n",
       "      <td>ENGINE_BEARINGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Repuestos Martillo Rotoprcutor Bosch Gshsce Po...</td>\n",
       "      <td>ELECTRIC_DEMOLITION_HAMMERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Pesca Caña Pejerrey Colony Brava 3m Fibra De V...</td>\n",
       "      <td>FISHING_RODS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Porcelanato Abitare Be 20x120 Cm. Ceramica Por...</td>\n",
       "      <td>PORCELAIN_TILES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Reconstruction Semi Di Lino Alfaparf Shampoo 1...</td>\n",
       "      <td>HAIR_SHAMPOOS_AND_CONDITIONERS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0                           Metal Biela Dw10 Hdi 2.0   \n",
       "1  Repuestos Martillo Rotoprcutor Bosch Gshsce Po...   \n",
       "2  Pesca Caña Pejerrey Colony Brava 3m Fibra De V...   \n",
       "3  Porcelanato Abitare Be 20x120 Cm. Ceramica Por...   \n",
       "4  Reconstruction Semi Di Lino Alfaparf Shampoo 1...   \n",
       "\n",
       "                         category  \n",
       "0                 ENGINE_BEARINGS  \n",
       "1     ELECTRIC_DEMOLITION_HAMMERS  \n",
       "2                    FISHING_RODS  \n",
       "3                 PORCELAIN_TILES  \n",
       "4  HAIR_SHAMPOOS_AND_CONDITIONERS  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_validacion = pd.read_csv(ARCHIVO_SET_DE_VALIDACION)\n",
    "\n",
    "print('Datos cargados con éxito, a continuación una muestra de los datos.')\n",
    "df_validacion.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06af3882",
   "metadata": {},
   "source": [
    "## Procesamiento de los títulos\n",
    "\n",
    "Extracción de títulos del dataframe de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7208469",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Títulos extraidos con éxito, a continuación una muestra de los mismos:\n",
      "\n",
      "Casita Muñecas Barbies Pintadas\n",
      "Neceser Cromado Holográfico \n",
      "Funda Asiento A Medida D20 Chevrolet\n",
      "Embrague Ford Focus One 1.8 8v Td (90cv) Desde 01-99\n",
      "Bateria Panasonic Dmwbcf10 Lumix Dmc-fx60n Dmcfx60n Fx60n\n",
      "Gurgel Br 800\n",
      "Harman Kardon Hk 3700 2ch Network Receiver _h\n",
      "Pack Netbook´s\n",
      "Olla Essen Duo\n",
      "Teclado Mini Bluetooth\n"
     ]
    }
   ],
   "source": [
    "if MUESTRAS > 0:\n",
    "    titulos = df_entrenamiento.sample(MUESTRAS).title.to_list()\n",
    "else:\n",
    "    titulos = df_entrenamiento.title.to_list()\n",
    "\n",
    "print('Títulos extraidos con éxito, a continuación una muestra de los mismos:\\n')\n",
    "for i in range(10):\n",
    "    print(titulos[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "606ec6dc",
   "metadata": {},
   "source": [
    "Extracción de los títulos del dataframe de validacion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3a1e36b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Títulos extraidos con éxito, a continuación una muestra de los mismos:\n",
      "\n",
      "Metal Biela Dw10 Hdi 2.0\n",
      "Repuestos Martillo Rotoprcutor Bosch Gshsce Por Separado\n",
      "Pesca Caña Pejerrey Colony Brava 3m Fibra De Vidrio 7 Sec\n",
      "Porcelanato Abitare Be 20x120 Cm. Ceramica Portinari\n",
      "Reconstruction Semi Di Lino Alfaparf Shampoo 1000 Ml\n",
      "Mascara Fotosensible Lüsqtoff, Oferta Y En Cuotas!\n",
      "Bermuda John Cena 14/16 Original\n",
      "20x Rueda Neumático Tuerca Set De 20 Lr068126 Oem Para Tierr\n",
      "Pelota De Basquet Spalding Tf-elite Nº 6\n",
      "Placard De Algarrobo Original 3 Puertas \n"
     ]
    }
   ],
   "source": [
    "titulos_validacion = df_validacion.title.to_list()\n",
    "\n",
    "print('Títulos extraidos con éxito, a continuación una muestra de los mismos:\\n')\n",
    "for i in range(10):\n",
    "    print(titulos_validacion[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37610287",
   "metadata": {},
   "source": [
    "Armado de un corpus de títulos de entrenamiento. El corpus contiene los títulos procesados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8d0598f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8083376d1aa44acba49bbce7611bf79d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando títulos:   0%|          | 0/4895280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han procesado 4895280 títulos.\n",
      "Muestra de los 5 primeros:\n",
      "\n",
      "['casita', 'muñecas', 'barbies', 'pintadas']\n",
      "['neceser', 'cromado', 'holográfico']\n",
      "['funda', 'asiento', 'medida', 'chevrolet']\n",
      "['embrague', 'ford', 'focus']\n",
      "['bateria', 'panasonic', 'dmwbcf', 'lumix', 'dmcfx']\n"
     ]
    }
   ],
   "source": [
    "corpus_titulos = []\n",
    "for titulo in tqdm(titulos, desc=\"Procesando títulos\"):\n",
    "    titulo_procesado = procesar_titulo(titulo)\n",
    "    corpus_titulos.append(titulo_procesado)\n",
    "# corpus_titulos contiene todos los títulos procesados.\n",
    "# Cada título es una lista de palabras procesadas\n",
    "print(f'Se han procesado {len(corpus_titulos)} títulos.\\nMuestra de los 5 primeros:\\n')\n",
    "for i in range(5):\n",
    "    print(corpus_titulos[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd43ca1",
   "metadata": {},
   "source": [
    "Armado de un corpus de títulos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7e92a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a77eb9855022499aacacdf2ee1d0ed28",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando títulos:   0%|          | 0/1223820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han procesado 1223820 títulos.\n",
      "Muestra de los 5 primeros:\n",
      "\n",
      "['metal', 'biela']\n",
      "['repuestos', 'martillo', 'rotoprcutor', 'bosch', 'gshsce', 'separado']\n",
      "['pesca', 'caña', 'pejerrey', 'colony', 'brava', 'fibra', 'vidrio']\n",
      "['porcelanato', 'abitare', 'ceramica', 'portinari']\n",
      "['reconstruction', 'semi', 'lino', 'alfaparf', 'shampoo']\n"
     ]
    }
   ],
   "source": [
    "corpus_titulos_validacion = []\n",
    "for titulo in tqdm(titulos_validacion, desc=\"Procesando títulos\"):\n",
    "    titulo_procesado = procesar_titulo(titulo)\n",
    "    corpus_titulos_validacion.append(titulo_procesado)\n",
    "\n",
    "print(f'Se han procesado {len(corpus_titulos_validacion)} títulos.\\nMuestra de los 5 primeros:\\n')\n",
    "for i in range(5):\n",
    "    print(corpus_titulos_validacion[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0109205",
   "metadata": {},
   "source": [
    "## Construcción del diccionario a partir del corpus de títulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6ed92e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando diccionario...\n",
      "Se generó un diccionario de longitud 50002 a partir de 4895280 documentos.\n",
      "Se guardó el diccionario en ./data/diccionario.txt.\n"
     ]
    }
   ],
   "source": [
    "# https://radimrehurek.com/gensim/corpora/dictionary.html\n",
    "print('Generando diccionario...')\n",
    "diccionario = corpora.Dictionary(corpus_titulos)\n",
    "diccionario.filter_extremes(no_below=2, no_above=1, keep_n=VOCAB_SIZE)\n",
    "diccionario.patch_with_special_tokens(TOKENS_ESPECIALES)\n",
    "diccionario.compactify()\n",
    "print(f'Se generó un diccionario de longitud {len(diccionario)} a partir de {diccionario.num_docs} documentos.')\n",
    "\n",
    "# Guardado del diccionario en archivo de texto\n",
    "diccionario.save_as_text(ARCHIVO_DICCIONARIO, sort_by_word=True)\n",
    "print(f'Se guardó el diccionario en {ARCHIVO_DICCIONARIO}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3e2ed7",
   "metadata": {},
   "source": [
    "## Encoding de datos\n",
    "\n",
    "Encoding de los títulos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d5152ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ac7b11f8edd4b1bbf6e07db4f37b2d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding de títulos:   0%|          | 0/4895280 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se realizó el encoding de los títulos.\n",
      "Muestra de los 5 primeros:\n",
      "\n",
      "[50001, 2, 50000, 3]\n",
      "[6, 4, 5]\n",
      "[9, 7, 10, 8]\n",
      "[11, 13, 12]\n",
      "[14, 18, 16, 17, 15]\n"
     ]
    }
   ],
   "source": [
    "encoded_titulos = []\n",
    "for titulo in tqdm(corpus_titulos, desc='Encoding de títulos'):\n",
    "    encoded_titulo = diccionario.doc2idx(titulo, unknown_word_index=1)\n",
    "    encoded_titulos.append(encoded_titulo)\n",
    "print('Se realizó el encoding de los títulos.\\nMuestra de los 5 primeros:\\n')\n",
    "for i in range(5):\n",
    "    print(encoded_titulos[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c034bcbb",
   "metadata": {},
   "source": [
    "Encoding de los títulos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "686a85db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffd105aed82448f8bcfe0d88a68a2507",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding de títulos:   0%|          | 0/1223820 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se realizó el encoding de los títulos.\n",
      "Muestra de los 5 primeros:\n",
      "\n",
      "[416, 1325]\n",
      "[2799, 798, 1, 688, 1, 8400]\n",
      "[629, 889, 1843, 3583, 3296, 1551, 1025]\n",
      "[2438, 3964, 1260, 3965]\n",
      "[1, 3017, 6739, 9836, 762]\n"
     ]
    }
   ],
   "source": [
    "encoded_titulos_validacion = []\n",
    "for titulo in tqdm(corpus_titulos_validacion, desc='Encoding de títulos'):\n",
    "    encoded_titulo = diccionario.doc2idx(titulo, unknown_word_index=1)\n",
    "    encoded_titulos_validacion.append(encoded_titulo)\n",
    "    \n",
    "print('Se realizó el encoding de los títulos.\\nMuestra de los 5 primeros:\\n')\n",
    "for i in range(5):\n",
    "    print(encoded_titulos_validacion[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8194d123",
   "metadata": {},
   "source": [
    "## Completamiento de datos\n",
    "\n",
    "Completamiento de los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "059394ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completamiento de datos.\n",
      "El título más largo tiene 17 palabras/indices.\n",
      "Se rellenó con 0 los valores faltantes en los títulos con menor longitud.\n",
      "\n",
      "[50001, 2, 50000, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[6, 4, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[9, 7, 10, 8, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[11, 13, 12, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[14, 18, 16, 17, 15, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print('Completamiento de datos.')\n",
    "longitudes_titulos = [len(titulo) for titulo in encoded_titulos]\n",
    "longitud_maxima = max(longitudes_titulos)\n",
    "print(f'El título más largo tiene {longitud_maxima} palabras/indices.')\n",
    "print(f'Se rellenó con {VALOR_DE_RELLENO} los valores faltantes en los títulos con menor longitud.\\n')\n",
    "data = [d[:ele] + [VALOR_DE_RELLENO] * (longitud_maxima - ele) for d, ele in zip(encoded_titulos, longitudes_titulos)]\n",
    "for i in range(5):\n",
    "    print(data[i])\n",
    "X_train = torch.LongTensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e25f05ae",
   "metadata": {},
   "source": [
    "Completamiento de los datos de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3dc5015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completamiento de datos.\n",
      "El título más largo tiene 16 palabras/indices.\n",
      "Se rellenó con 0 los valores faltantes en los títulos con menor longitud.\n",
      "\n",
      "[416, 1325, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[2799, 798, 1, 688, 1, 8400, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[629, 889, 1843, 3583, 3296, 1551, 1025, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[2438, 3964, 1260, 3965, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[1, 3017, 6739, 9836, 762, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print('Completamiento de datos.')\n",
    "longitudes_titulos = [len(titulo) for titulo in encoded_titulos_validacion]\n",
    "longitud_maxima = max(longitudes_titulos)\n",
    "print(f'El título más largo tiene {longitud_maxima} palabras/indices.')\n",
    "print(f'Se rellenó con {VALOR_DE_RELLENO} los valores faltantes en los títulos con menor longitud.\\n')\n",
    "data = [d[:ele] + [VALOR_DE_RELLENO] * (longitud_maxima - ele) for d, ele in zip(encoded_titulos_validacion, longitudes_titulos)]\n",
    "for i in range(5):\n",
    "    print(data[i])\n",
    "X_val = torch.LongTensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846df64a",
   "metadata": {},
   "source": [
    "## Conversión de categorías a etiquetas\n",
    "\n",
    "Función que convierte las categorías a etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "255a610b",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx_to_target = sorted(df_entrenamiento[\"category\"].unique())\n",
    "target_to_idx = {t: i for i, t in enumerate(idx_to_target)}\n",
    "def encode_target(target):\n",
    "    # Convierte las categorías a etiquetas\n",
    "    return target_to_idx[target]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691d9c1c",
   "metadata": {},
   "source": [
    "Conversión de categorías a etiquetas del dataframe de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d55d87c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se etiquetaron las categorías.\n",
      "Muestra de las 5 primeras:\n",
      "188\n",
      "570\n",
      "116\n",
      "25\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "categoria_etiquetada = [encode_target(t) for t in df_entrenamiento['category']]\n",
    "\n",
    "print('Se etiquetaron las categorías.\\nMuestra de las 5 primeras:')\n",
    "for i in range(5):\n",
    "    print(categoria_etiquetada[i])\n",
    "y_train = torch.LongTensor(categoria_etiquetada)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4764b89",
   "metadata": {},
   "source": [
    "Conversión de categorías a etiquetas del dataframe de validación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "70dbdf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se etiquetaron las categorías.\n",
      "Muestra de las 5 primeras:\n",
      "216\n",
      "202\n",
      "245\n",
      "467\n",
      "290\n"
     ]
    }
   ],
   "source": [
    "categoria_validacion_etiquetada = [encode_target(t) for t in df_validacion['category']]\n",
    "\n",
    "print('Se etiquetaron las categorías.\\nMuestra de las 5 primeras:')\n",
    "for i in range(5):\n",
    "    print(categoria_validacion_etiquetada[i])\n",
    "y_val = torch.LongTensor(categoria_validacion_etiquetada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "02c88543",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X_train, './data/X_train.pt')\n",
    "torch.save(y_train, './data/y_train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "fb967741",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(X_val, './data/X_val.pt')\n",
    "torch.save(y_val, './data/y_val.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15e087a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "del df_entrenamiento"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd06aa0",
   "metadata": {},
   "source": [
    "## Embedding de títulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "80989d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de la matriz de embeddings: torch.Size([50002, 300]).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0846a2d007504f6c917d88917eefe77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recorriendo archivo de embeddings:   0%|          | 0/1000654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizado el embedding de tamaño torch.Size([50002, 300]).\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding\n",
    "vector_size = 300\n",
    "embeddings_matrix = torch.randn(len(diccionario), vector_size)\n",
    "embeddings_matrix[0] = torch.zeros(vector_size)\n",
    "print(f'Tamaño de la matriz de embeddings: {embeddings_matrix.shape}.')\n",
    "with bz2.open(ARCHIVO_DE_EMBEDDINGS, mode='rt') as file:\n",
    "    for line in tqdm(file, total=1000654, desc=\"Recorriendo archivo de embeddings\"):\n",
    "        word, vector = line.strip().split(None, 1)\n",
    "        if word in diccionario.token2id:\n",
    "            embeddings_matrix[diccionario.token2id[word]] = torch.FloatTensor([float(n) for n in vector.split()])\n",
    "embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n",
    "                                          padding_idx=0)\n",
    "print(f'Finalizado el embedding de tamaño {embeddings.weight.shape}.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9f86a522",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embeddings_matrix, './data/embeddings_matrix.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
