{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad92109e",
   "metadata": {},
   "source": [
    "# Práctico 1 - Parte 2\n",
    "\n",
    "[Enunciado](https://github.com/DiploDatos/AprendizajeProfundo/blob/master/Practico.md) del trabajo práctico.\n",
    "\n",
    "**Implementación de red neuronal [Perceptrón Multicapa](https://en.wikipedia.org/wiki/Multilayer_perceptron) (MLP).**\n",
    "\n",
    "[Documentación de Pytorch](https://pytorch.org/docs/stable/index.html)\n",
    "\n",
    "[Tutorial](https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html)\n",
    "\n",
    "## Integrantes\n",
    "- Mauricio Caggia\n",
    "- Luciano Monforte\n",
    "- Gustavo Venchiarutti\n",
    "- Guillermo Robiglio\n",
    "\n",
    "En esta segunda parte se cargan datos reducidos en la parte 1. Esto con el fin de optimizar memoria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d74bd8",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8d08584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import bz2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from gensim import corpora\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "from practico1_modulo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e78fb0",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1fb3a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHIVO_SET_DE_ENTRENAMIENTO = './data/training_set.csv'\n",
    "ARCHIVO_SET_DE_ENTRENAMIENTO_REDUCIDO = './data/training_set_reduced.csv'\n",
    "ARCHIVO_SET_DE_PRUEBA = './data/test_set.csv'\n",
    "ARCHIVO_SET_DE_VALIDACION = './data/validation_set.csv'\n",
    "ARCHIVO_DE_EMBEDDINGS = './data/SBW-vectors-300-min5.txt.bz2'\n",
    "ARCHIVO_DICCIONARIO = './data/diccionario.txt'\n",
    "EPOCHS = 5\n",
    "VOCAB_SIZE = 1000 # Cantidad de palabras en el diccionario\n",
    "MUESTRAS = 10000 # Cantidad de muestras que se toman del set de entrenamiento\n",
    "                  # Si se configura valor 0 (cero) se toman todas las muestras\n",
    "TOKENS_ESPECIALES = {'[relleno]': 0, '[desconocido]': 1}\n",
    "VALOR_DE_RELLENO = 0\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd7676",
   "metadata": {},
   "source": [
    "## Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93f9d6c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos cargados con éxito, a continuación una muestra de los datos.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Casita Muñecas Barbies Pintadas</td>\n",
       "      <td>DOLLHOUSES</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Neceser Cromado Holográfico</td>\n",
       "      <td>TOILETRY_BAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Funda Asiento A Medida D20 Chevrolet</td>\n",
       "      <td>CAR_SEAT_COVERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Embrague Ford Focus One 1.8 8v Td (90cv) Desde...</td>\n",
       "      <td>AUTOMOTIVE_CLUTCH_KITS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bateria Panasonic Dmwbcf10 Lumix Dmc-fx60n Dmc...</td>\n",
       "      <td>CAMERA_BATTERIES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title                category\n",
       "0                    Casita Muñecas Barbies Pintadas              DOLLHOUSES\n",
       "1                       Neceser Cromado Holográfico            TOILETRY_BAGS\n",
       "2               Funda Asiento A Medida D20 Chevrolet         CAR_SEAT_COVERS\n",
       "3  Embrague Ford Focus One 1.8 8v Td (90cv) Desde...  AUTOMOTIVE_CLUTCH_KITS\n",
       "4  Bateria Panasonic Dmwbcf10 Lumix Dmc-fx60n Dmc...        CAMERA_BATTERIES"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_entrenamiento = pd.read_csv(ARCHIVO_SET_DE_ENTRENAMIENTO_REDUCIDO)\n",
    "if MUESTRAS > 0:\n",
    "    titulos = df_entrenamiento.sample(MUESTRAS).title.to_list()\n",
    "else:\n",
    "    titulos = df_entrenamiento.title.to_list()\n",
    "print('Datos cargados con éxito, a continuación una muestra de los datos.')\n",
    "df_entrenamiento.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06af3882",
   "metadata": {},
   "source": [
    "## Procesamiento de los títulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8d0598f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14b81725141246f087d5ec8402f80fb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Procesando títulos:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se han procesado 10000 títulos.\n",
      "Muestra de los 5 primeros:\n",
      "['campera', 'salida', 'racing', 'club', 'slim', 'celeste']\n",
      "['juego', 'disco', 'freno', 'fremax']\n",
      "['cargador', 'netbook', 'exelente']\n",
      "['rueda', 'giratoria', 'silla', 'escritorio', 'oficina']\n",
      "['collar', 'mariposas']\n"
     ]
    }
   ],
   "source": [
    "corpus_titulos = []\n",
    "for titulo in tqdm(titulos, desc=\"Procesando títulos\"):\n",
    "    titulo_procesado = procesar_titulo(titulo)\n",
    "    corpus_titulos.append(titulo_procesado)\n",
    "# corpus_titulos contiene todos los títulos procesados.\n",
    "# Cada título es una lista de palabras procesadas\n",
    "print(f'Se han procesado {len(corpus_titulos)} títulos.\\nMuestra de los 5 primeros:')\n",
    "for i in range(5):\n",
    "    print(corpus_titulos[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0109205",
   "metadata": {},
   "source": [
    "## Construcción del diccionario a partir del corpus de títulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ed92e5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generando diccionario...\n",
      "Se generó un diccionario de longitud 1002 a partir de 10000 documentos.\n",
      "Se guardó el diccionario en ./data/diccionario.txt.\n"
     ]
    }
   ],
   "source": [
    "# https://radimrehurek.com/gensim/corpora/dictionary.html\n",
    "print('Generando diccionario...')\n",
    "diccionario = corpora.Dictionary(corpus_titulos)\n",
    "diccionario.filter_extremes(no_below=2, no_above=0.5, keep_n=VOCAB_SIZE)\n",
    "diccionario.patch_with_special_tokens(TOKENS_ESPECIALES)\n",
    "diccionario.compactify()\n",
    "print(f'Se generó un diccionario de longitud {len(diccionario)} a partir de {diccionario.num_docs} documentos.')\n",
    "\n",
    "# Guardado del diccionario en archivo de texto\n",
    "diccionario.save_as_text(ARCHIVO_DICCIONARIO, sort_by_word=True)\n",
    "print(f'Se guardó el diccionario en {ARCHIVO_DICCIONARIO}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3e2ed7",
   "metadata": {},
   "source": [
    "## Encoding de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d5152ad0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e15790386dd4ef7ab8341dc996ff778",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Encoding de títulos:   0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se realizó el encoding de los títulos.\n",
      "Muestra de los 5 primeros:\n",
      "[1000, 3, 2, 1, 4, 1001]\n",
      "[7, 5, 6, 1]\n",
      "[8, 1, 1]\n",
      "[11, 1, 12, 9, 10]\n",
      "[13, 1]\n"
     ]
    }
   ],
   "source": [
    "encoded_titulos = []\n",
    "for titulo in tqdm(corpus_titulos, desc='Encoding de títulos'):\n",
    "    encoded_titulo = diccionario.doc2idx(titulo, unknown_word_index=1)\n",
    "    encoded_titulos.append(encoded_titulo)\n",
    "print('Se realizó el encoding de los títulos.\\nMuestra de los 5 primeros:')\n",
    "for i in range(5):\n",
    "    print(encoded_titulos[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8194d123",
   "metadata": {},
   "source": [
    "## Completamiento de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3dc5015",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completamiento de datos.\n",
      "El título más largo tiene 14 palabras/indices.\n",
      "Se rellenará con 0 los valores faltantes en los títulos que tengan menor longitud.\n",
      "[1000, 3, 2, 1, 4, 1001, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[7, 5, 6, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[8, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[11, 1, 12, 9, 10, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[13, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print('Completamiento de datos.')\n",
    "longitudes_titulos = [len(titulo) for titulo in encoded_titulos]\n",
    "longitud_maxima = max(longitudes_titulos)\n",
    "print(f'El título más largo tiene {longitud_maxima} palabras/indices.')\n",
    "print(f'Se rellenará con {VALOR_DE_RELLENO} los valores faltantes en los títulos que tengan menor longitud.')\n",
    "data = [d[:ele] + [VALOR_DE_RELLENO] * (longitud_maxima - ele) for d, ele in zip(encoded_titulos, longitudes_titulos)]\n",
    "for i in range(5):\n",
    "    print(data[i])\n",
    "X = torch.LongTensor(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846df64a",
   "metadata": {},
   "source": [
    "## Conversión de categorías a etiquetas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "255a610b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Se etiquetaron las categorías.\n",
      "Muestra de las 5 primeras:\n",
      "188\n",
      "570\n",
      "116\n",
      "25\n",
      "103\n"
     ]
    }
   ],
   "source": [
    "idx_to_target = sorted(df_entrenamiento[\"category\"].unique())\n",
    "target_to_idx = {t: i for i, t in enumerate(idx_to_target)}\n",
    "def encode_target(target):\n",
    "    # Convierte las categorías a etiquetas\n",
    "    return target_to_idx[target]\n",
    "categoria_etiquetada = [encode_target(t) for t in df_entrenamiento['category']]\n",
    "print('Se etiquetaron las categorías.\\nMuestra de las 5 primeras:')\n",
    "for i in range(5):\n",
    "    print(categoria_etiquetada[i])\n",
    "y = torch.LongTensor(categoria_etiquetada)\n",
    "\n",
    "torch.save(X, './data/X_train.pt')\n",
    "torch.save(y, './data/y_train.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd06aa0",
   "metadata": {},
   "source": [
    "## Embedding de títulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "80989d2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tamaño de la matriz de embeddings: torch.Size([1002, 300]).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27245a5c23d34482b86efb16883d33b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Recorriendo archivo de embeddings:   0%|          | 0/1000654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finalizado el embedding de tamaño torch.Size([1002, 300]).\n"
     ]
    }
   ],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding\n",
    "vector_size = 300\n",
    "embeddings_matrix = torch.randn(len(diccionario), vector_size)\n",
    "embeddings_matrix[0] = torch.zeros(vector_size)\n",
    "print(f'Tamaño de la matriz de embeddings: {embeddings_matrix.shape}.')\n",
    "with bz2.open(ARCHIVO_DE_EMBEDDINGS, mode='rt') as file:\n",
    "    for line in tqdm(file, total=1000654, desc=\"Recorriendo archivo de embeddings\"):\n",
    "        word, vector = line.strip().split(None, 1)\n",
    "        if word in diccionario.token2id:\n",
    "            embeddings_matrix[diccionario.token2id[word]] = torch.FloatTensor([float(n) for n in vector.split()])\n",
    "embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n",
    "                                          padding_idx=0)\n",
    "print(f'Finalizado el embedding de tamaño {embeddings.weight.shape}.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1d327",
   "metadata": {},
   "source": [
    "## Construcción del Dataset\n",
    "\n",
    "El dataset se construye a partir del dataframe de Pandas que tiene dos columnas:\n",
    "- **title**\n",
    "- **category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "230d33c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "{'data': tensor([21,  1,  1,  1,  1,  1,  1,  0,  0,  0,  0,  0,  0,  0]), 'target': tensor(1)}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "435b1d67821341dbaf1f3f3d62237eea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/100 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 iteraciones\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MeLiChallengeDataset(X, y)\n",
    "print(len(train_dataset))\n",
    "print(train_dataset[10])\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          drop_last=False)\n",
    "i = 0\n",
    "for data in tqdm(train_loader):\n",
    "    i += 1\n",
    "print(f'{i} iteraciones')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e833f",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los datos\n",
    "\n",
    "El preprocesamiento de texto tiene dos propósitos:\n",
    "- Tokenizar los títulos (datos) de modo que se quiten los signos de puntuación y palabras cortas como preposiciones y conjunciones (stopwords), todas las palabras queden en minúsculas, se separen en listas de palabras, etc.\n",
    "- Transformar las categorías en etiquetas numéricas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720625c",
   "metadata": {},
   "source": [
    "## Carga del Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f7f30",
   "metadata": {},
   "source": [
    "## Construcción del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d1ae4f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeLiChallengeClassifier(nn.Module):\n",
    "    def __init__(self, \n",
    "                 pretrained_embeddings_path, \n",
    "                 dictionary,\n",
    "                 vector_size,\n",
    "                 freeze_embedings):\n",
    "        super().__init__()\n",
    "        embeddings_matrix = torch.randn(len(dictionary), vector_size)\n",
    "        embeddings_matrix[0] = torch.zeros(vector_size)\n",
    "        with gzip.open(pretrained_embeddings_path, encode='utf-8', \"rt\") as fh:\n",
    "#       with bz2.open(pretrained_embeddings_path, \"rt\") as fh:\n",
    "            for line in fh:\n",
    "                word, vector = line.strip().split(None, 1)\n",
    "                if word in dictionary.token2id:\n",
    "                    embeddings_matrix[dictionary.token2id[word]] = torch.FloatTensor([float(n) for n in vector.split()])\n",
    "        self.embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n",
    "                                                       freeze=freeze_embedings,\n",
    "                                                       padding_idx=0)\n",
    "        self.hidden1 = nn.Linear(vector_size, 128)\n",
    "        self.hidden2 = nn.Linear(128, 128)\n",
    "        self.output = nn.Linear(128, 632)\n",
    "        self.vector_size = vector_size\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.embeddings(x)\n",
    "        x = torch.mean(x, dim=1)\n",
    "        x = F.relu(self.hidden1(x))\n",
    "        x = F.relu(self.hidden2(x))\n",
    "        x = torch.sigmoid(self.output(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274fe854",
   "metadata": {},
   "source": [
    "## Algoritmo de Optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "65a15de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.69 s, sys: 53 ms, total: 1.74 s\n",
      "Wall time: 1.76 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "model = MeLiChallengeClassifier(ARCHIVO_DE_EMBEDDINGS, train_processor.dictionary, 50, True)\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7772d8",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4dfe282f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando cuda:0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MeLiChallengeClassifier(\n",
       "  (embeddings): Embedding(5002, 50, padding_idx=0)\n",
       "  (hidden1): Linear(in_features=50, out_features=128, bias=True)\n",
       "  (hidden2): Linear(in_features=128, out_features=128, bias=True)\n",
       "  (output): Linear(in_features=128, out_features=632, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Utilizando {device}')\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9777a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# for epoch in range(EPOCHS):  # Recorre el dataset multiples veces\n",
    "#     model.train()\n",
    "#     running_loss = 0.0\n",
    "#     for data in train_loader:\n",
    "#         inputs = data['data'].to(device)\n",
    "#         labels = data['target'].to(device)\n",
    "#         optimizer.zero_grad()\n",
    "#         outputs = model(inputs)\n",
    "#         loss = loss_function(outputs, labels.squeeze().long())\n",
    "#         loss.backward()\n",
    "#         optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4b74ecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.train()\n",
    "# for data in train_loader:\n",
    "#     inputs = data['data'].to(device)\n",
    "#     target = data['target'].to(device)\n",
    "#     optimizer.zero_grad()\n",
    "#     output = model(inputs)\n",
    "#     loss = loss_function(output, target)\n",
    "#     loss.backward()\n",
    "#     optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "208c28aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    for batch, data in enumerate(dataloader):\n",
    "        X, y = data['data'].to(device), data['target'].to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378dee4",
   "metadata": {},
   "source": [
    "## Evaluación del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "745425ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in dataloader:\n",
    "            X, y = data['data'].to(device), data['target'].to(device)\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "aa966304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n",
      "loss: 6.448280  [    0/20000]\n",
      "Test Error: \n",
      " Accuracy: 0.1%, Avg loss: 6.448738 \n",
      "\n",
      "Epoch 2\n",
      "-------------------------------\n",
      "loss: 6.448425  [    0/20000]\n",
      "Test Error: \n",
      " Accuracy: 0.1%, Avg loss: 6.448745 \n",
      "\n",
      "Epoch 3\n",
      "-------------------------------\n",
      "loss: 6.448981  [    0/20000]\n",
      "Test Error: \n",
      " Accuracy: 0.1%, Avg loss: 6.448733 \n",
      "\n",
      "Epoch 4\n",
      "-------------------------------\n",
      "loss: 6.448917  [    0/20000]\n",
      "Test Error: \n",
      " Accuracy: 0.1%, Avg loss: 6.448730 \n",
      "\n",
      "Epoch 5\n",
      "-------------------------------\n",
      "loss: 6.448575  [    0/20000]\n",
      "Test Error: \n",
      " Accuracy: 0.1%, Avg loss: 6.448724 \n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train(train_loader, model, loss_function, optimizer)\n",
    "    test(test_loader, model, loss_function)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "82f873c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for batch, data in enumerate(train_loader):\n",
    "#     i += 1\n",
    "#     print (f'Lote {i}.')\n",
    "#     if i%10 == 0:\n",
    "#         print(type(data['data']))\n",
    "#         print(type(data['target']))\n",
    "# print(f'{i} iteraciones.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e169eaaa",
   "metadata": {},
   "source": [
    "## Guardado de los parámetros del modelo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
