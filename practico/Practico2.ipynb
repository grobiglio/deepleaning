{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad92109e",
   "metadata": {},
   "source": [
    "# Práctico 2\n",
    "\n",
    "[Enunciado](https://github.com/DiploDatos/AprendizajeProfundo/blob/master/Practico.md) del trabajo práctico.\n",
    "\n",
    "**Implementación de red neuronal [Red Neuronal Recurrente Long Short Term Memory](https://en.wikipedia.org/wiki/Long_short-term_memory) (LSTM).**\n",
    "\n",
    "## Integrantes\n",
    "- Mauricio Caggia\n",
    "- Luciano Monforte\n",
    "- Gustavo Venchiarutti\n",
    "- Guillermo Robiglio\n",
    "\n",
    "La razón por la que se escoigió una Red Neuronal Recurrente obedece a que la misma tiene aplicaciones en el Procesamiento del Lenguaje Natural.\n",
    "\n",
    "En particular, se utiliza una RNN del tipo **many to one** debido a que la entrada es una secuencia de palabras tokenizadas y codificadas, y la salida en un valor entero correspondiente a la etiqueta de una categoría. Cabe aclarar también que NO se trata de una RNN bidireccional porque usa información soalmente de la izquierda del contexto. Como utiliza la información procesada del trabajo práctico 1, se usan secuencias cortas (longitud 17 para el set de entrenamiento)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d74bd8",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d08584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from practico1_modulo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e78fb0",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1fb3a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd7676",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Carga de datos de entrenamiento. Son los mismos datos que se utilizaron para el Trabajo Práctico 1. Para más información consultar archivo [Practico_1.md](https://github.com/grobiglio/deepleaning/blob/master/practico/Practico_1.md#deep-learning---trabajo-pr%C3%A1ctico-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c88543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2329329/1027201965.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(torch.load('./data/y_train.pt'), dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.load('./data/X_train.pt')\n",
    "# y_train = torch.load('./data/y_train.pt')\n",
    "y_train = torch.tensor(torch.load('./data/y_train.pt'), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c4ec4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000, 17])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducción del dataset de entrenamiento es temporal\n",
    "# Cuando compruebe que funciona se eliminará esta celda.\n",
    "X_train = X_train[:1000000]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2005ef17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducción del dataset de entrenamiento es temporal\n",
    "# Cuando compruebe que funciona se eliminará esta celda.\n",
    "y_train = y_train[:1000000]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599bcadc",
   "metadata": {},
   "source": [
    "Carga de datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6081c5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2329329/2269913238.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(torch.load('./data/y_test.pt'), dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "X_test = torch.load('./data/X_test.pt')\n",
    "# y_test = torch.load('./data/y_test.pt')\n",
    "y_test = torch.tensor(torch.load('./data/y_test.pt'), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc46469e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500000, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducción del dataset de prueba es temporal.\n",
    "# Cuando compruebe que funciona se eliminará esta celda.\n",
    "X_test = X_test[:500000]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb67b68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducción del dataset de prueba es temporal.\n",
    "# Cuando compruebe que funciona se eliminará esta celda.\n",
    "y_test = y_test[:500000]\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd06aa0",
   "metadata": {},
   "source": [
    "## Embedding de títulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80989d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding\n",
    "embeddings_matrix = torch.load('./data/embeddings_matrix.pt')\n",
    "embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n",
    "                                          padding_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1d327",
   "metadata": {},
   "source": [
    "## Construcción del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "230d33c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3a0ae7eb6f4e79a4364fe58c18bd1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorrida exitosa de 10000 batches de entrenamiento.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781708aeafc348179c92f8bc7d13596f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorrida exitosa de 5000 batches de prueba.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MeLiChallengeDataset(X_train, y_train)\n",
    "test_dataset = MeLiChallengeDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          drop_last=False)\n",
    "i = 0\n",
    "for data in tqdm(train_loader):\n",
    "    i += 1\n",
    "print(f'Recorrida exitosa de {i} batches de entrenamiento.')\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         drop_last=False)\n",
    "i = 0\n",
    "for data in tqdm(test_loader):\n",
    "    i += 1\n",
    "print(f'Recorrida exitosa de {i} batches de prueba.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f7f30",
   "metadata": {},
   "source": [
    "## Construcción del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3bb04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeLiChallengeLSTM(nn.Module):\n",
    "    def __init__(self, embeddings):\n",
    "        super(MeLiChallengeLSTM, self).__init__()\n",
    "        self.embeddings = embeddings\n",
    "        output_size = 1\n",
    "        self.lstm_config = {'input_size': 300,\n",
    "                            'hidden_size': 150, # tamaño de la capa oculta\n",
    "                            'num_layers': 1,\n",
    "                            'bias': True,\n",
    "                            'batch_first': True,\n",
    "                            'dropout': 0,\n",
    "                            'bidirectional': False,\n",
    "                            'proj_size': 0}\n",
    "        \n",
    "        # Set our fully connected layer parameters\n",
    "        self.linear_config = {'in_features': 150,\n",
    "                              'out_features': output_size,\n",
    "                              'bias': True}\n",
    "        \n",
    "        # Instanciate the layers\n",
    "        # Documentación LSTM 👉 https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "        self.lstm = nn.LSTM(**self.lstm_config)\n",
    "        self.classification_layer = nn.Linear(**self.linear_config)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        emb = self.embeddings(inputs)\n",
    "        lstm_out, _ = self.lstm(emb) # guardo el estado y descarto el contexto\n",
    "        lstm_out = lstm_out[:, -1, :].squeeze() # guardo el último estado\n",
    "        predictions = self.activation(self.classification_layer(lstm_out))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a636a42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeLiChallengeLSTM(\n",
      "  (embeddings): Embedding(50002, 300, padding_idx=0)\n",
      "  (lstm): LSTM(300, 150, batch_first=True)\n",
      "  (classification_layer): Linear(in_features=150, out_features=1, bias=True)\n",
      "  (activation): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modelo = MeLiChallengeLSTM(embeddings)\n",
    "print(modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274fe854",
   "metadata": {},
   "source": [
    "## Algoritmo de Optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "65a15de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.Adam(modelo.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dfe282f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MeLiChallengeLSTM(\n",
       "  (embeddings): Embedding(50002, 300, padding_idx=0)\n",
       "  (lstm): LSTM(300, 150, batch_first=True)\n",
       "  (classification_layer): Linear(in_features=150, out_features=1, bias=True)\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Utilizando {device}')\n",
    "modelo.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7772d8",
   "metadata": {},
   "source": [
    "## Entrenamiento y evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c27edad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    '''Entrenamiento de una red neuronal.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    - dataloader: Iterador (objeto) de Pytorch construido en base al dataset basado en la clase MeLiChallengeDataset.\n",
    "    - model: Modelo (objeto) basado en la clase MeLiChallengeClassifier.\n",
    "    - loss_fn: Función de costo.\n",
    "    - optimizer: Optimizador.\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    train_loss: Valor promedio de la función de costo minimizados de cada uno de los batches.\n",
    "    \n",
    "    '''\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    running_loss = []\n",
    "    for batch, data in enumerate(tqdm(dataloader)):\n",
    "        X, y = data['data'].to(device), data['target'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X) # Esto devuelve siempre un tensor de unos, por eso no funciona 😡\n",
    "        loss = loss_fn(pred.squeeze(), y) # Aquí se compara un tensor de unos con los valores verdaderos\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss.append(loss.item())\n",
    "        train_loss = sum(running_loss) / len(running_loss)\n",
    "        \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e2a8bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    '''Evaluación de una red neuronal.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    - dataloader: Iterador (objeto) de Pytorch construido en base al dataset basado en la clase MeLiChallengeDataset.\n",
    "    - model: Modelo (objeto) basado en la clase MeLiChallengeClassifier.\n",
    "    - loss_fn: Función de costo.\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    - train_loss: Valor promedio de la función de costo minimizados de cada uno de los batches.\n",
    "    - avp: Precisión.\n",
    "    '''\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    running_loss = []\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataloader):\n",
    "            X, y = data['data'].to(device), data['target'].to(device)\n",
    "            pred = model(X) # Esto devuelve siempre un tensor de unos, por eso no funciona 😡\n",
    "            running_loss.append(loss_function(pred.squeeze(), y).item())\n",
    "            targets.extend(y.cpu().detach().numpy())\n",
    "            predictions.extend(pred.squeeze().cpu().round().detach().numpy())\n",
    "            \n",
    "        test_loss = sum(running_loss) / len(running_loss)\n",
    "        avp = balanced_accuracy_score(targets, predictions)\n",
    "                                    \n",
    "    return test_loss, avp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be87f5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57860c29b4aa4880b27ec5879769be53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final train_loss -30997.030854624772\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b5f04a2c809241728feb8457b8e5ac6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final test_loss -31219.0474\n",
      "\t Final test_avp 0.0015822784810126582\n",
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00eb7160abad41b4bde32f96fd4acb22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final train_loss -31227.0784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a222c029d0ce42dab04dd8045cab30d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final test_loss -31219.0474\n",
      "\t Final test_avp 0.0015822784810126582\n",
      "Epoch 3\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52bf4bd32de34c74bc0caab114794f5f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final train_loss -31227.0784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f48ddd8d6e2a45de844c0a0c58984ff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final test_loss -31219.0474\n",
      "\t Final test_avp 0.0015822784810126582\n",
      "!Listo!\n"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    'train_loss': [],\n",
    "    'test_loss': [],\n",
    "    'test_avp': []\n",
    "}\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train(train_loader, modelo, loss_function, optimizer)\n",
    "    print(\"\\t Final train_loss\", train_loss)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    test_loss, avp = test(test_loader, modelo, loss_function)\n",
    "    print(\"\\t Final test_loss\", test_loss)\n",
    "    print(\"\\t Final test_avp\", avp)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_avp'].append(avp)\n",
    "print(\"!Listo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccefb1c9",
   "metadata": {},
   "source": [
    "## ¿Por qué no funciona?\n",
    "\n",
    "No funciona porque el modelo devuelve siempre un tensor de unos. Evidentemente hay un problema con el modelo.\n",
    "\n",
    "Logramos entender el funcionamiento de la RNN LSTM pero no logramos que aún funcione."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
