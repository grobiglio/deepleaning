{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad92109e",
   "metadata": {},
   "source": [
    "# Pr谩ctico 2\n",
    "\n",
    "[Enunciado](https://github.com/DiploDatos/AprendizajeProfundo/blob/master/Practico.md) del trabajo pr谩ctico.\n",
    "\n",
    "**Implementaci贸n de red neuronal [Red Neuronal Recurrente Long Short Term Memory](https://en.wikipedia.org/wiki/Long_short-term_memory) (LSTM).**\n",
    "\n",
    "## Integrantes\n",
    "- Mauricio Caggia\n",
    "- Luciano Monforte\n",
    "- Gustavo Venchiarutti\n",
    "- Guillermo Robiglio\n",
    "\n",
    "La raz贸n por la que se escoigi贸 una Red Neuronal Recurrente obedece a que la misma tiene aplicaciones en el Procesamiento del Lenguaje Natural.\n",
    "\n",
    "En particular, se utiliza una RNN del tipo **many to one** debido a que la entrada es una secuencia de palabras tokenizadas y codificadas, y la salida es un valor entero correspondiente a la etiqueta de una categor铆a. Cabe aclarar tambi茅n que NO se trata de una RNN bidireccional porque usa informaci贸n soalmente de la izquierda del contexto. Como utiliza la informaci贸n procesada del trabajo pr谩ctico 1, se usan secuencias cortas (longitud 17 para el set de entrenamiento)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d74bd8",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d08584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from practico1_modulo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e78fb0",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "1fb3a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd7676",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Carga de datos de entrenamiento. Son los mismos datos que se utilizaron para el Trabajo Pr谩ctico 1. Para m谩s informaci贸n consultar archivo [Practico_1.md](https://github.com/grobiglio/deepleaning/blob/master/practico/Practico_1.md#deep-learning---trabajo-pr%C3%A1ctico-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "02c88543",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1728891/1027201965.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(torch.load('./data/y_train.pt'), dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "X_train = torch.load('./data/X_train.pt')\n",
    "# y_train = torch.load('./data/y_train.pt')\n",
    "y_train = torch.tensor(torch.load('./data/y_train.pt'), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "5c4ec4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000000, 17])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducci贸n del dataset de entrenamiento es temporal\n",
    "# Cuando compruebe que funciona se eliminar谩 esta celda.\n",
    "X_train = X_train[:2000000]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "2005ef17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2000000])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducci贸n del dataset de entrenamiento es temporal\n",
    "# Cuando compruebe que funciona se eliminar谩 esta celda.\n",
    "y_train = y_train[:2000000]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599bcadc",
   "metadata": {},
   "source": [
    "Carga de datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6081c5b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1728891/205465924.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_test = torch.tensor(torch.load('./data/y_val.pt'), dtype=torch.float)\n"
     ]
    }
   ],
   "source": [
    "X_test = torch.load('./data/X_val.pt')\n",
    "y_test = torch.tensor(torch.load('./data/y_val.pt'), dtype=torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc46469e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500000, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducci贸n del dataset de prueba es temporal.\n",
    "# Cuando compruebe que funciona se eliminar谩 esta celda.\n",
    "X_test = X_test[:500000]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb67b68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducci贸n del dataset de prueba es temporal.\n",
    "# Cuando compruebe que funciona se eliminar谩 esta celda.\n",
    "y_test = y_test[:500000]\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd06aa0",
   "metadata": {},
   "source": [
    "## Embedding de t铆tulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "80989d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding\n",
    "embeddings_matrix = torch.load('./data/embeddings_matrix.pt')\n",
    "embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n",
    "                                          padding_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1d327",
   "metadata": {},
   "source": [
    "## Construcci贸n del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "230d33c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "950e95ae638e4e9eb6ce9aa44e4d2442",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorrida exitosa de 20000 batches de entrenamiento.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e340f77b0d194e3a832df2aa25d3715d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorrida exitosa de 5000 batches de validaci贸n.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MeLiChallengeDataset(X_train, y_train)\n",
    "test_dataset = MeLiChallengeDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          drop_last=False)\n",
    "i = 0\n",
    "for data in tqdm(train_loader):\n",
    "    i += 1\n",
    "print(f'Recorrida exitosa de {i} batches de entrenamiento.')\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         drop_last=False)\n",
    "i = 0\n",
    "for data in tqdm(test_loader):\n",
    "    i += 1\n",
    "print(f'Recorrida exitosa de {i} batches de validaci贸n.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f7f30",
   "metadata": {},
   "source": [
    "## Construcci贸n del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "e3bb04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeLiChallengeLSTM(nn.Module):\n",
    "    def __init__(self, embeddings):\n",
    "        super(MeLiChallengeLSTM, self).__init__()\n",
    "        self.embeddings = embeddings\n",
    "        output_size = 632\n",
    "        self.lstm_config = {'input_size': 300,\n",
    "                            'hidden_size': 300, # tama帽o de la capa oculta\n",
    "                            'num_layers': 1,\n",
    "                            'bias': True,\n",
    "                            'batch_first': True,\n",
    "                            'dropout': 0,\n",
    "                            'bidirectional': False,\n",
    "                            'proj_size': 0}\n",
    "        \n",
    "        # Set our fully connected layer parameters\n",
    "        self.linear_config = {'in_features': 300,\n",
    "                              'out_features': output_size,\n",
    "                              'bias': True}\n",
    "        \n",
    "        # Instanciate the layers\n",
    "        # Documentaci贸n LSTM  https://pytorch.org/docs/stable/generated/torch.nn.LSTM.html\n",
    "        self.lstm = nn.LSTM(**self.lstm_config)\n",
    "        self.classification_layer = nn.Linear(**self.linear_config)\n",
    "        self.activation = nn.Softmax(dim=0)\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        emb = self.embeddings(inputs)\n",
    "        lstm_out, _ = self.lstm(emb) # guardo el estado y descarto el contexto\n",
    "        lstm_out = lstm_out[:, -1, :].squeeze() # guardo el 煤ltimo estado\n",
    "        predictions = self.activation(self.classification_layer(lstm_out))\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a636a42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeLiChallengeLSTM(\n",
      "  (embeddings): Embedding(50002, 300, padding_idx=0)\n",
      "  (lstm): LSTM(300, 300, batch_first=True)\n",
      "  (classification_layer): Linear(in_features=300, out_features=632, bias=True)\n",
      "  (activation): Softmax(dim=0)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modelo = MeLiChallengeLSTM(embeddings)\n",
    "print(modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274fe854",
   "metadata": {},
   "source": [
    "## Algoritmo de Optimizaci贸n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "65a15de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(modelo.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "4dfe282f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MeLiChallengeLSTM(\n",
       "  (embeddings): Embedding(50002, 300, padding_idx=0)\n",
       "  (lstm): LSTM(300, 300, batch_first=True)\n",
       "  (classification_layer): Linear(in_features=300, out_features=632, bias=True)\n",
       "  (activation): Softmax(dim=0)\n",
       ")"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Utilizando {device}')\n",
    "modelo.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7772d8",
   "metadata": {},
   "source": [
    "## Entrenamiento y evaluaci贸n del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "c27edad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    '''Entrenamiento de una red neuronal.\n",
    "    \n",
    "    Par谩metros:\n",
    "    -----------\n",
    "    - dataloader: Iterador (objeto) de Pytorch construido en base al dataset basado en la clase MeLiChallengeDataset.\n",
    "    - model: Modelo (objeto) basado en la clase MeLiChallengeClassifier.\n",
    "    - loss_fn: Funci贸n de costo.\n",
    "    - optimizer: Optimizador.\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    train_loss: Valor promedio de la funci贸n de costo minimizados de cada uno de los batches.\n",
    "    \n",
    "    '''\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    running_loss = []\n",
    "    for batch, data in enumerate(tqdm(dataloader)):\n",
    "        X, y = data['data'].to(device), data['target'].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = torch.tensor(torch.argmax(model(X), dim=1), # Tensor de 100 x 1 donde cada elemento es el label predicho de la categor铆a\n",
    "                            dtype=torch.float,\n",
    "                            requires_grad=True)\n",
    "#         if batch % 5000 == 0:\n",
    "#             print('Prediction:', pred)\n",
    "#             print('y:', y)\n",
    "        loss = loss_fn(pred.squeeze(), y) # Aqu铆 se compara un tensor de unos con los valores verdaderos\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss.append(loss.item())\n",
    "        train_loss = sum(running_loss) / len(running_loss)\n",
    "        \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "e2a8bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    '''Evaluaci贸n de una red neuronal.\n",
    "    \n",
    "    Par谩metros:\n",
    "    -----------\n",
    "    - dataloader: Iterador (objeto) de Pytorch construido en base al dataset basado en la clase MeLiChallengeDataset.\n",
    "    - model: Modelo (objeto) basado en la clase MeLiChallengeClassifier.\n",
    "    - loss_fn: Funci贸n de costo.\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    - train_loss: Valor promedio de la funci贸n de costo minimizados de cada uno de los batches.\n",
    "    - avp: Precisi贸n.\n",
    "    '''\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    running_loss = []\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataloader):\n",
    "            X, y = data['data'].to(device), data['target'].to(device)\n",
    "            pred = torch.tensor(torch.argmax(model(X), dim=1), dtype=torch.float)\n",
    "            running_loss.append(loss_function(pred.squeeze(), y).item())\n",
    "            targets.extend(y.cpu().detach().numpy())\n",
    "            predictions.extend(pred.squeeze().cpu().round().detach().numpy())\n",
    "            \n",
    "        test_loss = sum(running_loss) / len(running_loss)\n",
    "        avp = balanced_accuracy_score(targets, predictions)\n",
    "                                    \n",
    "    return test_loss, avp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "be87f5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a10d6f6280064f28959eeee3e6c4d06f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1728891/4159431462.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred = torch.tensor(torch.argmax(model(X), dim=1), # Tensor de 100 x 1 donde cada elemento es el label predicho de la categor铆a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final train_loss 11186408.30190625\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97eb911f44bd40bf9b4147a57355b37c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1728891/3452802198.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred = torch.tensor(torch.argmax(model(X), dim=1), dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final test_loss 10983606.5855\n",
      "\t Final test_avp 0.0014505292252790603\n",
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "349b8d338f2a4ba48534dbec85b172c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1728891/4159431462.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred = torch.tensor(torch.argmax(model(X), dim=1), # Tensor de 100 x 1 donde cada elemento es el label predicho de la categor铆a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final train_loss 11189362.000775\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcd446b0f6274859ae7ed8fc27fe6854",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1728891/3452802198.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred = torch.tensor(torch.argmax(model(X), dim=1), dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final test_loss 10991737.7552\n",
      "\t Final test_avp 0.001440423052031227\n",
      "Epoch 3\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "447ae69e806149bcabe01dbb65608366",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1728891/4159431462.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred = torch.tensor(torch.argmax(model(X), dim=1), # Tensor de 100 x 1 donde cada elemento es el label predicho de la categor铆a\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final train_loss 11203296.47233125\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7659dc10e4c4cdaa3abc60df006f3db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1728891/3452802198.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pred = torch.tensor(torch.argmax(model(X), dim=1), dtype=torch.float)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final test_loss 10985870.1261\n",
      "\t Final test_avp 0.0014178413434114223\n",
      "!Listo!\n"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    'train_loss': [],\n",
    "    'test_loss': [],\n",
    "    'test_avp': []\n",
    "}\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train(train_loader, modelo, loss_function, optimizer)\n",
    "    print(\"\\t Final train_loss\", train_loss)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    test_loss, avp = test(test_loader, modelo, loss_function)\n",
    "    print(\"\\t Final test_loss\", test_loss)\n",
    "    print(\"\\t Final test_avp\", avp)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_avp'].append(avp)\n",
    "print(\"!Listo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccefb1c9",
   "metadata": {},
   "source": [
    "## 驴Por qu茅 no funciona?\n",
    "\n",
    "Si bien se tuvo 茅xtito en la implementaci贸n de la funci贸n de activaci贸n Softmax, por alguna raz贸n que merece ser investigada no est谩 prediciendo correctamente las etiquetas.\n",
    "\n",
    "Logramos entender el funcionamiento de la RNN LSTM pero no logramos que a煤n funcione.\n",
    "Logramos implementar la funci贸n de costo CrossEntropyLoss y el activador Softmax que devielve eun vector con valores entre 0 y 1, siendo esto la probabilidad que corresponda a la etiqueta asociada al 铆ndice.\n",
    "\n",
    "Se pudo comparar valores predichos con las etiquetas y calcular el accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
