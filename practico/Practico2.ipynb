{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad92109e",
   "metadata": {},
   "source": [
    "# Práctico 1 - Parte 3 de 3\n",
    "\n",
    "[Enunciado](https://github.com/DiploDatos/AprendizajeProfundo/blob/master/Practico.md) del trabajo práctico.\n",
    "\n",
    "**Implementación de red neuronal [Perceptrón Multicapa](https://en.wikipedia.org/wiki/Multilayer_perceptron) (MLP).**\n",
    "\n",
    "## Integrantes\n",
    "- Mauricio Caggia\n",
    "- Luciano Monforte\n",
    "- Gustavo Venchiarutti\n",
    "- Guillermo Robiglio\n",
    "\n",
    "En esta tercera parte se arman los datasets, los dataloaders y se entrena y prueba el modelo.\n",
    "\n",
    "## ⚠ IMPORTANTE ⚠\n",
    "\n",
    "Por favor leer el archivo [Practico_1.md](https://github.com/grobiglio/deepleaning/blob/master/practico/Practico_1.md#deep-learning---trabajo-pr%C3%A1ctico-1) que se encuentra en el repositorio donde se puso este trabajo práctico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d74bd8",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8d08584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "import tempfile\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from gensim import corpora\n",
    "from tqdm.notebook import tqdm, trange\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from practico1_modulo import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e78fb0",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1fb3a4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "BATCH_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd7676",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Carga de datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "02c88543",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.load('./data/X_train.pt')\n",
    "y_train = torch.load('./data/y_train.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c4ec4da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000, 17])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducción del dataset de entrenamiento es temporal\n",
    "# Cuando compruebe que funciona se eliminará esta celda.\n",
    "X_train = X_train[:1000000]\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2005ef17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1000000])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducción del dataset de entrenamiento es temporal\n",
    "# Cuando compruebe que funciona se eliminará esta celda.\n",
    "y_train = y_train[:1000000]\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "599bcadc",
   "metadata": {},
   "source": [
    "Carga de datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6081c5b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.load('./data/X_test.pt')\n",
    "y_test = torch.load('./data/y_test.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fc46469e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500000, 16])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducción del dataset de prueba es temporal.\n",
    "# Cuando compruebe que funciona se eliminará esta celda.\n",
    "X_test = X_test[:500000]\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb67b68f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([500000])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# La reducción del dataset de prueba es temporal.\n",
    "# Cuando compruebe que funciona se eliminará esta celda.\n",
    "y_test = y_test[:500000]\n",
    "y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd06aa0",
   "metadata": {},
   "source": [
    "## Embedding de títulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80989d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://pytorch.org/docs/stable/generated/torch.nn.Embedding.html#torch.nn.Embedding\n",
    "embeddings_matrix = torch.load('./data/embeddings_matrix.pt')\n",
    "embeddings = nn.Embedding.from_pretrained(embeddings_matrix,\n",
    "                                          padding_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1d327",
   "metadata": {},
   "source": [
    "## Construcción del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "230d33c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d754c436fce5452d94366b8ac7a1658b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorrida exitosa de 10000 batches de entrenamiento.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d44ee62fdbd244958bd1228f2abfec40",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorrida exitosa de 5000 batches de prueba.\n"
     ]
    }
   ],
   "source": [
    "train_dataset = MeLiChallengeDataset(X_train, y_train)\n",
    "test_dataset = MeLiChallengeDataset(X_test, y_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset,\n",
    "                          batch_size=BATCH_SIZE,\n",
    "                          shuffle=True,\n",
    "                          drop_last=False)\n",
    "i = 0\n",
    "for data in tqdm(train_loader):\n",
    "    i += 1\n",
    "print(f'Recorrida exitosa de {i} batches de entrenamiento.')\n",
    "\n",
    "test_loader = DataLoader(test_dataset,\n",
    "                         batch_size=BATCH_SIZE,\n",
    "                         shuffle=True,\n",
    "                         drop_last=False)\n",
    "i = 0\n",
    "for data in tqdm(test_loader):\n",
    "    i += 1\n",
    "print(f'Recorrida exitosa de {i} batches de prueba.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f7f30",
   "metadata": {},
   "source": [
    "## Construcción del Modelo\n",
    "\n",
    "[Red Neuronal Recurrente Long Short Term Memory (LSTM)](https://en.wikipedia.org/wiki/Long_short-term_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e3bb04b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeLiChallengeLSTM(nn.Module):\n",
    "    def __init__(self, embeddings):\n",
    "        super(MeLiChallengeLSTM, self).__init__()\n",
    "        output_size = 1\n",
    "        # Create the Embeddings layer and add pre-trained weights\n",
    "        self.embeddings = embeddings\n",
    "        \n",
    "        # Set our LSTM parameters\n",
    "        embedding_size = 300\n",
    "        hidden_layer = 32\n",
    "        num_layers = 1\n",
    "        bias = True\n",
    "        dropout = 0\n",
    "        bidirectional = False\n",
    "        self.lstm_config = {'input_size': embedding_size,\n",
    "                            'hidden_size': hidden_layer,\n",
    "                            'num_layers': num_layers,\n",
    "                            'bias': bias,\n",
    "                            'batch_first': True,\n",
    "                            'dropout': dropout,\n",
    "                            'bidirectional': bidirectional}\n",
    "        \n",
    "        # Set our fully connected layer parameters\n",
    "        self.linear_config = {'in_features': hidden_layer,\n",
    "                              'out_features': output_size,\n",
    "                              'bias': bias}\n",
    "        \n",
    "        # Instanciate the layers\n",
    "        self.lstm = nn.LSTM(**self.lstm_config)\n",
    "        self.classification_layer = nn.Linear(**self.linear_config)\n",
    "        self.activation = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        emb = self.embeddings(inputs)\n",
    "        # print(emb.shape)\n",
    "        lstm_out, _ = self.lstm(emb)\n",
    "        # print(lstm_out.shape)\n",
    "        # Take last state of lstm, which is a representation of\n",
    "        # the entire text\n",
    "        lstm_out = lstm_out[:, -1, :].squeeze()\n",
    "        # print(lstm_out.shape)\n",
    "        predictions = self.activation(self.classification_layer(lstm_out))\n",
    "        # print(prediction.shape)\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a636a42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MeLiChallengeLSTM(\n",
      "  (embeddings): Embedding(50002, 300, padding_idx=0)\n",
      "  (lstm): LSTM(300, 32, batch_first=True)\n",
      "  (classification_layer): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (activation): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "modelo = MeLiChallengeLSTM(embeddings)\n",
    "print(modelo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274fe854",
   "metadata": {},
   "source": [
    "## Algoritmo de Optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65a15de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "loss_function = nn.BCELoss()\n",
    "optimizer = optim.Adam(modelo.parameters(), learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4dfe282f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Utilizando cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MeLiChallengeLSTM(\n",
       "  (embeddings): Embedding(50002, 300, padding_idx=0)\n",
       "  (lstm): LSTM(300, 32, batch_first=True)\n",
       "  (classification_layer): Linear(in_features=32, out_features=1, bias=True)\n",
       "  (activation): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Utilizando {device}')\n",
    "modelo.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7772d8",
   "metadata": {},
   "source": [
    "## Entrenamiento y evaluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c27edad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    '''Entrenamiento de una red neuronal.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    - dataloader: Iterador (objeto) de Pytorch construido en base al dataset basado en la clase MeLiChallengeDataset.\n",
    "    - model: Modelo (objeto) basado en la clase MeLiChallengeClassifier.\n",
    "    - loss_fn: Función de costo.\n",
    "    - optimizer: Optimizador.\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    train_loss: Valor promedio de la función de costo minimizados de cada uno de los batches.\n",
    "    \n",
    "    '''\n",
    "    size = len(dataloader.dataset)\n",
    "    model.train()\n",
    "    running_loss = []\n",
    "    for batch, data in enumerate(tqdm(dataloader)):\n",
    "        X, y = data['data'].to(device), torch.tensor(data['target'], dtype=torch.float32, device=device)\n",
    "        optimizer.zero_grad()\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred.squeeze(), y)\n",
    "        # pred: Dimensión 100 x 632\n",
    "        # y: Dimensión 100\n",
    "        # Por eso esto no funciona 😡 ¿Cómo se soluciona? 😡\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss.append(loss.item())\n",
    "        train_loss = sum(running_loss) / len(running_loss)\n",
    "        \n",
    "    return train_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "e2a8bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(dataloader, model, loss_fn):\n",
    "    '''Evaluación de una red neuronal.\n",
    "    \n",
    "    Parámetros:\n",
    "    -----------\n",
    "    - dataloader: Iterador (objeto) de Pytorch construido en base al dataset basado en la clase MeLiChallengeDataset.\n",
    "    - model: Modelo (objeto) basado en la clase MeLiChallengeClassifier.\n",
    "    - loss_fn: Función de costo.\n",
    "    \n",
    "    Salidas:\n",
    "    --------\n",
    "    - train_loss: Valor promedio de la función de costo minimizados de cada uno de los batches.\n",
    "    - avp: Precisión.\n",
    "    '''\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    model.eval()\n",
    "    running_loss = []\n",
    "    targets = []\n",
    "    predictions = []\n",
    "    test_loss, correct = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm(dataloader):\n",
    "            X, y = data['data'].to(device), torch.tensor(data['target'], dtype=torch.float32, device=device)\n",
    "            pred = model(X)\n",
    "            running_loss.append(loss_function(output.squeeze(), y).item())\n",
    "            targets.extend(y.cpu().detach().numpy())\n",
    "            predictions.extend(output.squeeze().cpu().round().detach().numpy())\n",
    "            \n",
    "        test_loss = sum(running_loss) / len(running_loss)\n",
    "        avp = balanced_accuracy_score(targets, predictions)\n",
    "                                    \n",
    "    return test_loss, avp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "be87f5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8e4bc02dbe24b0a8c531ae7270fec1c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2446845/477588734.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X, y = data['data'].to(device), torch.tensor(data['target'], dtype=torch.float32, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final train_loss -31227.0784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ff30b82597a4de68c14650c4078768d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2446845/437957924.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X, y = data['data'].to(device), torch.tensor(data['target'], dtype=torch.float32, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final test_loss -31219.0474\n",
      "\t Final test_avp 0.0015822784810126582\n",
      "Epoch 2\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "474a3ed04d7b4930a6721ad519f70d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2446845/477588734.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X, y = data['data'].to(device), torch.tensor(data['target'], dtype=torch.float32, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final train_loss -31227.0784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c7ce11bb6734ed5ac2d185311358d02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2446845/437957924.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X, y = data['data'].to(device), torch.tensor(data['target'], dtype=torch.float32, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final test_loss -31219.0474\n",
      "\t Final test_avp 0.0015822784810126582\n",
      "Epoch 3\n",
      "-------------------------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1393c093cc384adf975a1f57b1ec91a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2446845/477588734.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X, y = data['data'].to(device), torch.tensor(data['target'], dtype=torch.float32, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final train_loss -31227.0784\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a5ec3b8367542afb98c6fcf99790dc2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2446845/437957924.py:24: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  X, y = data['data'].to(device), torch.tensor(data['target'], dtype=torch.float32, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t Final test_loss -31219.0474\n",
      "\t Final test_avp 0.0015822784810126582\n",
      "!Listo!\n"
     ]
    }
   ],
   "source": [
    "history = {\n",
    "    'train_loss': [],\n",
    "    'test_loss': [],\n",
    "    'test_avp': []\n",
    "}\n",
    "\n",
    "for t in range(EPOCHS):\n",
    "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
    "    train_loss = train(train_loader, modelo, loss_function, optimizer)\n",
    "    print(\"\\t Final train_loss\", train_loss)\n",
    "    history['train_loss'].append(train_loss)\n",
    "    test_loss, avp = test(test_loader, modelo, loss_function)\n",
    "    print(\"\\t Final test_loss\", test_loss)\n",
    "    print(\"\\t Final test_avp\", avp)\n",
    "    history['test_loss'].append(test_loss)\n",
    "    history['test_avp'].append(avp)\n",
    "print(\"!Listo!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccefb1c9",
   "metadata": {},
   "source": [
    "## ¿Por qué sospechamos que no funciona?\n",
    "\n",
    "Falta explicar porqué no funciona."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
