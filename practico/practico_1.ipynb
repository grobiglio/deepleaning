{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad92109e",
   "metadata": {},
   "source": [
    "# Pr√°ctico 1\n",
    "\n",
    "[Enunciado](https://github.com/DiploDatos/AprendizajeProfundo/blob/master/Practico.md) del trabajo pr√°ctico.\n",
    "\n",
    "**Implementaci√≥n de red neuronal [Perceptr√≥n Multicapa](https://en.wikipedia.org/wiki/Multilayer_perceptron) (MLP).**\n",
    "\n",
    "## Integrantes\n",
    "- Mauricio Caggia\n",
    "- Luciano Monforte\n",
    "- Gustavo Venchiarutti\n",
    "- Guillermo Robiglio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d74bd8",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d08584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e78fb0",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d5a343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHIVO_SET_DE_ENTRENAMIENTO = './data/meli-challenge-2019/spanish.train.jsonl.gz'\n",
    "ARCHIVO_DE_ENTRENAMIENTO_REDUCIDO = './data/train.json'\n",
    "ARCHIVO_SET_DE_PRUEBA = './data/meli-challenge-2019/spanish.test.jsonl.gz'\n",
    "ARCHIVO_DE_PRUEBA_REDUCIDO = './data/test.json'\n",
    "ARCHIVO_SET_DE_VALIDACION = './data/meli-challenge-2019/spanish.validation.jsonl.gz'\n",
    "ARCHIVO_DE_VALIDACION_REDUCIDO = './data/validation.json'\n",
    "ARCHIVO_TOKENS = './data/meli-challenge-2019/spanish_token_to_index.json.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd7676",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Completa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc2d537d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file_paths = [ARCHIVO_SET_DE_ENTRENAMIENTO, # Ingresar opci√≥n 0 üëÅ ‚ö† Tarda m√°s de 2 minutos en cargar y puede que haya un desbordamiento de RAM o muera el kernel‚ö†\n",
    "              ARCHIVO_SET_DE_PRUEBA,  # Ingresar opci√≥n 1\n",
    "              ARCHIVO_SET_DE_VALIDACION] # Ingresar opci√≥n 2 ‚ö† Tarda m√°s de 30 segundos en cargar\n",
    "i = int(input('Ingresar opci√≥n para carga de archivo (0 a 2): '))\n",
    "df = pd.read_json(path_or_buf=file_paths[i], lines=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95506576",
   "metadata": {},
   "source": [
    "Reducida"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16f87a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "file_paths = [ARCHIVO_DE_ENTRENAMIENTO_REDUCIDO, # Ingresar opci√≥n 0\n",
    "              ARCHIVO_DE_PRUEBA_REDUCIDO, # Ingresar opci√≥n 1\n",
    "              ARCHIVO_DE_VALIDACION_REDUCIDO] # Ingresar opci√≥n 2\n",
    "i = int(input('Ingresar opci√≥n para carga de archivo (0 a 2): '))\n",
    "df_reducido = pd.read_json(path_or_buf=file_paths[i], lines=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5d8b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = pd.read_json(path_or_buf=ARCHIVO_TOKENS, lines=True).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1304190e",
   "metadata": {},
   "source": [
    "## An√°lisis y visualizaci√≥n de los datos\n",
    "\n",
    "El **set de entrenamiento** original tiene 4895280 registros con valores no nulos y 10 columnas. Las columnas de dicho dataset son:\n",
    "- **language**: El idioma del dataset (espa√±or o portugu√©s). En el trabajo pr√°ctico utilizaremos solamente el dataset es espa√±ol.\n",
    "- **label_quality**: Calidad de la etiqueta (confiable o no confiable). Se dispone de 4508043 registros no confiables y 387237 registros confiables.\n",
    "- **title**: El t√≠tulo que se asign√≥ al producto.\n",
    "- **category**: La categor√≠a que se asign√≥ al producto.\n",
    "- **split**: El tipo de dataset. _train_ para el set de entrenamiento.\n",
    "- **tokenized_title**: El t√≠tulo tokenizado. Esto significa que los datos fueron preprocesados.\n",
    "- **data**: El n√∫mero asignado a cada palabra del t√≠tulo tokenizado. Esta informaci√≥n es la que se utilizar√° para entrenar el modelo.\n",
    "- **target**: El n√∫mero que corresponde a cada categor√≠a.\n",
    "- **n_labels**: Cantidad de etiquetas num√©ricas correspondientes a las distintas categor√≠as. 632 etiquetas (0 a 631) para el caso del set de entrenamiento.\n",
    "- **size**: La cantidad de registros. 4895280 registros para el caso del set de entrenamiento.\n",
    "\n",
    "El **set de prueba** original tiene 63680 registros con valores no nulos y 10 columnas. Las columnas de dicho dataset son:\n",
    "- **language**: El idioma del dataset (espa√±or o portugu√©s). En el trabajo pr√°ctico utilizaremos solamente el dataset es espa√±ol.\n",
    "- **label_quality**: Calidad de la etiqueta (confiable o no confiable). Todas las etiquetas de este dataset son confiables.\n",
    "- **title**: El t√≠tulo que se asign√≥ al producto.\n",
    "- **category**: La categor√≠a que se asign√≥ al producto.\n",
    "- **split**: El tipo de dataset. _test_ para el set de prueba.\n",
    "- **tokenized_title**: El t√≠tulo tokenizado. Esto significa que los datos fueron preprocesados.\n",
    "- **data**: El n√∫mero asignado a cada palabra del t√≠tulo tokenizado. Esta informaci√≥n es la que se utilizar√° para entrenar el modelo.\n",
    "- **target**: El n√∫mero que corresponde a cada categor√≠a.\n",
    "- **n_labels**: Cantidad de etiquetas num√©ricas correspondientes a las distintas categor√≠as. 632 etiquetas (0 a 631) para el caso del set de prueba.\n",
    "- **size**: La cantidad de registros. 63680 registros para el caso del set de prueba.\n",
    "\n",
    "El **set de validaci√≥n** original tiene 1223820 registros con valores no nulos y 10 columnas. Las columnas de dicho dataset son:\n",
    "- **language**: El idioma del dataset (espa√±or o portugu√©s). En el trabajo pr√°ctico utilizaremos solamente el dataset es espa√±ol.\n",
    "- **label_quality**: Calidad de la etiqueta (confiable o no confiable). Se dispone de 1127189 registros no confiables y 96631 registros confiables.\n",
    "- **title**: El t√≠tulo que se asign√≥ al producto.\n",
    "- **category**: La categor√≠a que se asign√≥ al producto.\n",
    "- **split**: El tipo de dataset. _validation_ para el set de prueba.\n",
    "- **tokenized_title**: El t√≠tulo tokenizado. Esto significa que los datos fueron preprocesados.\n",
    "- **data**: El n√∫mero asignado a cada palabra del t√≠tulo tokenizado. Esta informaci√≥n es la que se utilizar√° para entrenar el modelo.\n",
    "- **target**: El n√∫mero que corresponde a cada categor√≠a.\n",
    "- **n_labels**: Cantidad de etiquetas num√©ricas correspondientes a las distintas categor√≠as. 632 etiquetas (0 a 631) para el caso del set de validaci√≥n.\n",
    "- **size**: La cantidad de registros. 1223820 registros para el caso del set de validaci√≥n.\n",
    "\n",
    "El archivo **spanish_token_to_index** tiene las 50002 correspondencias que existen entre las palabras tokenizadas del t√≠tulo y las etiquetas num√©ricas bajo la columna data en los sets de entrenamiento, prueba y validaci√≥n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c08a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2739ad5",
   "metadata": {},
   "source": [
    "La siguiente celda se utiliza para reducir el dataset a partir del dataset completo.\n",
    "\n",
    "Un atajo es cargar directamente el dataset reducido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8935d60",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reducido = df.drop(columns=['language', 'label_quality', 'title',\n",
    "                               'category', 'split', 'tokenized_title',\n",
    "                               'n_labels', 'size'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0e7aa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reducido.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff73c0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_reducido.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0299dfb1",
   "metadata": {},
   "source": [
    "Las siguientes tres celdas se utilizan una √∫nica vez para guardar un dataset reducido para cada conjunto de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781187e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_reducido.to_json(ARCHIVO_DE_ENTRENAMIENTO_REDUCIDO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f499f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_reducido.to_json(ARCHIVO_DE_PRUEBA_REDUCIDO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b8796a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_reducido.to_json(ARCHIVO_DE_VALIDACION_REDUCIDO)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4a3a632",
   "metadata": {},
   "source": [
    "### La columna *data*\n",
    "\n",
    "El **dataset de entrenamiento** posee un total de 26129139 etiquetas (que se corresponden con una palabra toquenizada) comprendidad entre el 1 y el 50001, esto es, 50001 etiquetas diferentes que permiten anticipar que el tensor que se utilizar√° para el entrenamiento de la red neuronal tendr√° una dimensi√≥n de 4895280 x 50001.\n",
    "\n",
    "El **dataset de prueba** posee un total de 354208 etiquetas (que se corresponden con una palabra toquenizada) comprendidas entre el 1 y el 50001. En este conjunto de datos hay 25741 etiquetas diferentes. El tensor tendr√° una dimensi√≥n de 63680 x 50001.\n",
    "\n",
    "El **dataset de validaci√≥n** posee un total de 6531439 etiquetas (que se corresponden con una palabra toquenizada) comprendidas entre el 1 y el 50001. En este conjunto de datos hay 49961 etiquetas diferentes. El tensor tendr√° una dimensi√≥n de 1223820 x 50001.\n",
    "\n",
    "**NOTA**: En ninguno de los casos aparece la etiqueta 0, por eso aqu√≠ hay un elemento menos que en la lista de las etiquetas de palabras tokenizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c039b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_reducido.data\n",
    "\n",
    "lista_num_palabras = []\n",
    "for id_palabras in data:\n",
    "    lista_num_palabras += id_palabras\n",
    "    \n",
    "\n",
    "print('Cantidad de etiquetas:', len(lista_num_palabras))\n",
    "print('Cantidad de etiquetas diferentes:', len(set(lista_num_palabras)))\n",
    "print('Valor m√°ximo:', max(lista_num_palabras))\n",
    "print('Valor m√≠nimo:', min(lista_num_palabras))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee1dad4",
   "metadata": {},
   "source": [
    "### La columna *target*\n",
    "\n",
    "Contiene un n√∫mero entero correspondiente a cada categor√≠a. 632 etiquetas entre 0 y 631."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d0729d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df_reducido.target.unique()\n",
    "print(f'{labels.shape[0]} etiquetas ordenadas como se muestra a continuaci√≥n:')\n",
    "np.sort(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d67367",
   "metadata": {},
   "source": [
    "### Tokens y sus etiquetas\n",
    "\n",
    "Las siguientes 3 celdas de c√≥digo demuestran que la relaci√≥n entre los datos bajo las columnas `tokenized_title` y `data` est√° dada en el archivo `spanish_token_to_index` que vincula cada palabra a un √≠ndice num√©rico entero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f7cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 # Un √≠ndice cualquiera para extraer datos\n",
    "items = df.at[i, 'tokenized_title']\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477604c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar la salida de esta celda con la de la siguiente\n",
    "df.at[i, 'data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nro_items = []\n",
    "for item in items:\n",
    "    id_item = tokens.loc[item][0]\n",
    "    nro_items.append(id_item)\n",
    "nro_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1d327",
   "metadata": {},
   "source": [
    "## Construcci√≥n del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087eb2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "filas = df_reducido.shape[0]\n",
    "columnas = 50001\n",
    "esqueleto = np.zeros((filas, columnas), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2bc017",
   "metadata": {},
   "outputs": [],
   "source": [
    "matriz = pd.DataFrame(esqueleto, columns=range(1,columnas+1))\n",
    "matriz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1468a4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_reducido)):\n",
    "    lista_de_etiquetas = df_reducido.iloc[i, 0]\n",
    "    for etiqueta in lista_de_etiquetas:\n",
    "        matriz.iloc[i, etiqueta-1] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee304b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.tensor(matriz.values).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdc0555",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrimerDataset(Dataset):\n",
    "    def __init__(self, df_reducido):\n",
    "        self.df_reducido = df_reducido\n",
    "    \n",
    "    def __len__(self):\n",
    "        pass\n",
    "    \n",
    "    def __getitem__(self):\n",
    "        pass\n",
    "    \n",
    "    def hacer_esqueleto(self):\n",
    "        filas = self.df_reducido.shape[0]\n",
    "        columnas = 50001\n",
    "        esqueleto = np.zeros((filas, columnas), dtype=np.int8)\n",
    "        return esqueleto\n",
    "    \n",
    "    def hacer_matriz(self, esqueleto):\n",
    "        matriz = pd.DataFrame(esqueleto, columns=range(1,columnas+1))\n",
    "    \n",
    "primer_dataset = PrimerDataset()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3497bd8",
   "metadata": {},
   "source": [
    "## Dataset de PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77568602",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeLiChallengeDataset(IterableDataset):\n",
    "    def __init__(self):\n",
    "        opcion = input('¬øQu√© dataset quer√©s cargar ([train]/test/valid)? ')\n",
    "        if opcion == 'test':\n",
    "            self.file_path = './data/meli-challenge-2019/spanish.test.jsonl.gz'\n",
    "        elif opcion == 'valid':\n",
    "            self.file_path = './data/meli-challenge-2019/spanish.validation.jsonl.gz'\n",
    "        else:\n",
    "            self.file_path = './data/meli-challenge-2019/spanish.train.jsonl.gz'\n",
    "        \n",
    "    def __iter__(self):\n",
    "        print('Cargando', self.file_path)\n",
    "        with gzip.open(self.file_path, \"rt\") as file:\n",
    "            for line in file:\n",
    "                data = json.loads(line)\n",
    "                item = {\n",
    "                    \"data\": self.crear_fila_del_tensor(),\n",
    "                    \"target\": data['target']\n",
    "                }\n",
    "                yield item\n",
    "                \n",
    "    def crear_fila_del_tensor(self):\n",
    "        tensor = torch.tensor((), dtype=torch.int8)\n",
    "        return tensor.new_zeros(10)\n",
    "\n",
    "dataset = MeLiChallengeDataset()\n",
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=False, num_workers=0)\n",
    "dataiter = iter(dataloader)\n",
    "print(f\"Sample batch:\\n{dataiter.next()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8617273e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor = torch.tensor((), dtype=torch.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c23e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.new_zeros((200, 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f7f30",
   "metadata": {},
   "source": [
    "## Construcci√≥n del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7772d8",
   "metadata": {},
   "source": [
    "## Optimizador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for input, target in dataset:\n",
    "    optimizer.zero_grad()\n",
    "    output = model(input)\n",
    "    loss = loss_fn(output, target)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47dd2c4",
   "metadata": {},
   "source": [
    "## Entrenamiento del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378dee4",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e169eaaa",
   "metadata": {},
   "source": [
    "## Guardado de los par√°metros del modelo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
