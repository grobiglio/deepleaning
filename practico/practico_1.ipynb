{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad92109e",
   "metadata": {},
   "source": [
    "# Pr√°ctico 1\n",
    "\n",
    "[Enunciado](https://github.com/DiploDatos/AprendizajeProfundo/blob/master/Practico.md) del trabajo pr√°ctico.\n",
    "\n",
    "**Implementaci√≥n de red neuronal [Perceptr√≥n Multicapa](https://en.wikipedia.org/wiki/Multilayer_perceptron) (MLP).**\n",
    "\n",
    "## Integrantes\n",
    "- Mauricio Caggia\n",
    "- Luciano Monforte\n",
    "- Gustavo Venchiarutti\n",
    "- Guillermo Robiglio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2d74bd8",
   "metadata": {},
   "source": [
    "## Importaciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8d08584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "import functools\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, IterableDataset\n",
    "from gensim.parsing import preprocessing\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e78fb0",
   "metadata": {},
   "source": [
    "## Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d5a343d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARCHIVO_SET_DE_ENTRENAMIENTO = './data/meli-challenge-2019/spanish.train.jsonl.gz'\n",
    "ARCHIVO_SET_DE_PRUEBA = './data/meli-challenge-2019/spanish.test.jsonl.gz'\n",
    "ARCHIVO_SET_DE_VALIDACION = './data/meli-challenge-2019/spanish.validation.jsonl.gz'\n",
    "ARCHIVO_TOKENS = './data/meli-challenge-2019/spanish_token_to_index.json.gz'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fd7676",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "\n",
    "Esta carga de datos se realiza con el fin de explorar los mismos. Otra carga de datos tendr√° lugar al comento de construir el dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc2d537d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ingresar opci√≥n para carga de archivo (0 a 2): 1\n",
      "CPU times: user 861 ms, sys: 130 ms, total: 990 ms\n",
      "Wall time: 4.43 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "file_paths = [ARCHIVO_SET_DE_ENTRENAMIENTO, # Ingresar opci√≥n 0 üëÅ ‚ö† Tarda m√°s de 2 minutos en cargar y puede que haya un desbordamiento de RAM o muera el kernel‚ö†\n",
    "              ARCHIVO_SET_DE_PRUEBA,  # Ingresar opci√≥n 1\n",
    "              ARCHIVO_SET_DE_VALIDACION] # Ingresar opci√≥n 2 ‚ö† Tarda m√°s de 30 segundos en cargar\n",
    "i = int(input('Ingresar opci√≥n para carga de archivo (0 a 2): '))\n",
    "df = pd.read_json(path_or_buf=file_paths[i], lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5d8b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = pd.read_json(path_or_buf=ARCHIVO_TOKENS, lines=True).T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1304190e",
   "metadata": {},
   "source": [
    "## An√°lisis y visualizaci√≥n de los datos\n",
    "\n",
    "El **set de entrenamiento** original tiene 4895280 registros con valores no nulos y 10 columnas. Las columnas de dicho dataset son:\n",
    "- **language**: El idioma del dataset (espa√±or o portugu√©s). En el trabajo pr√°ctico utilizaremos solamente el dataset es espa√±ol.\n",
    "- **label_quality**: Calidad de la etiqueta (confiable o no confiable). Se dispone de 4508043 registros no confiables y 387237 registros confiables.\n",
    "- **title**: El t√≠tulo que se asign√≥ al producto. **Esta informaci√≥n es la que se utilizar√° para armar el dataser de entrenamiento.**\n",
    "- **category**: La categor√≠a que se asign√≥ al producto. **Este es el target**.\n",
    "- **split**: El tipo de dataset. _train_ para el set de entrenamiento.\n",
    "- **tokenized_title**: El t√≠tulo tokenizado. Esto significa que los datos fueron preprocesados.\n",
    "- **data**: El n√∫mero asignado a cada palabra del t√≠tulo tokenizado.\n",
    "- **target**: El n√∫mero que corresponde a cada categor√≠a.\n",
    "- **n_labels**: Cantidad de etiquetas num√©ricas correspondientes a las distintas categor√≠as. 632 etiquetas (0 a 631) para el caso del set de entrenamiento.\n",
    "- **size**: La cantidad de registros. 4895280 registros para el caso del set de entrenamiento.\n",
    "\n",
    "El **set de prueba** original tiene 63680 registros con valores no nulos y 10 columnas. Las columnas de dicho dataset son:\n",
    "- **language**: El idioma del dataset (espa√±or o portugu√©s). En el trabajo pr√°ctico utilizaremos solamente el dataset es espa√±ol.\n",
    "- **label_quality**: Calidad de la etiqueta (confiable o no confiable). Todas las etiquetas de este dataset son confiables.\n",
    "- **title**: El t√≠tulo que se asign√≥ al producto.\n",
    "- **category**: La categor√≠a que se asign√≥ al producto.\n",
    "- **split**: El tipo de dataset. _test_ para el set de prueba.\n",
    "- **tokenized_title**: El t√≠tulo tokenizado. Esto significa que los datos fueron preprocesados.\n",
    "- **data**: El n√∫mero asignado a cada palabra del t√≠tulo tokenizado.\n",
    "- **target**: El n√∫mero que corresponde a cada categor√≠a.\n",
    "- **n_labels**: Cantidad de etiquetas num√©ricas correspondientes a las distintas categor√≠as. 632 etiquetas (0 a 631) para el caso del set de prueba.\n",
    "- **size**: La cantidad de registros. 63680 registros para el caso del set de prueba.\n",
    "\n",
    "El **set de validaci√≥n** original tiene 1223820 registros con valores no nulos y 10 columnas. Las columnas de dicho dataset son:\n",
    "- **language**: El idioma del dataset (espa√±or o portugu√©s). En el trabajo pr√°ctico utilizaremos solamente el dataset es espa√±ol.\n",
    "- **label_quality**: Calidad de la etiqueta (confiable o no confiable). Se dispone de 1127189 registros no confiables y 96631 registros confiables.\n",
    "- **title**: El t√≠tulo que se asign√≥ al producto.\n",
    "- **category**: La categor√≠a que se asign√≥ al producto.\n",
    "- **split**: El tipo de dataset. _validation_ para el set de prueba.\n",
    "- **tokenized_title**: El t√≠tulo tokenizado. Esto significa que los datos fueron preprocesados.\n",
    "- **data**: El n√∫mero asignado a cada palabra del t√≠tulo tokenizado.\n",
    "- **target**: El n√∫mero que corresponde a cada categor√≠a.\n",
    "- **n_labels**: Cantidad de etiquetas num√©ricas correspondientes a las distintas categor√≠as. 632 etiquetas (0 a 631) para el caso del set de validaci√≥n.\n",
    "- **size**: La cantidad de registros. 1223820 registros para el caso del set de validaci√≥n.\n",
    "\n",
    "El archivo **spanish_token_to_index** tiene las 50002 correspondencias que existen entre las palabras tokenizadas del t√≠tulo y las etiquetas num√©ricas bajo la columna data en los sets de entrenamiento, prueba y validaci√≥n. No se utilizar√° este tokenizador, en lugar de ello se utilizar√° ...\n",
    "\n",
    "**En este trabajo pr√°ctico se utiliza:**\n",
    "- El **set de entrenamiento** para entrenar el modelo\n",
    "- El **set de validaci√≥n** para evaluar el modelo y ajustar hiperpar√°metros\n",
    "- El **set de prueba** para mostrar el mejor modelo obtenido"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56c08a2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>label_quality</th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "      <th>split</th>\n",
       "      <th>tokenized_title</th>\n",
       "      <th>data</th>\n",
       "      <th>target</th>\n",
       "      <th>n_labels</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>spanish</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Mochilas Maternales Bolsos Bebe Simil Cuero Ma...</td>\n",
       "      <td>DIAPER_BAGS</td>\n",
       "      <td>test</td>\n",
       "      <td>[mochilas, maternales, bolsos, bebe, simil, cu...</td>\n",
       "      <td>[5650, 5271, 5268, 915, 2724, 375, 37363]</td>\n",
       "      <td>318</td>\n",
       "      <td>632</td>\n",
       "      <td>63680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spanish</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Bolso Maternal/bebe Incluye Cambiador + Correa...</td>\n",
       "      <td>DIAPER_BAGS</td>\n",
       "      <td>test</td>\n",
       "      <td>[bolso, maternal, bebe, incluye, cambiador, co...</td>\n",
       "      <td>[502, 2742, 915, 3031, 2740, 1840, 4635]</td>\n",
       "      <td>318</td>\n",
       "      <td>632</td>\n",
       "      <td>63680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>spanish</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Mochila Maternal Land  + Gancho Envio Gratis-cc</td>\n",
       "      <td>DIAPER_BAGS</td>\n",
       "      <td>test</td>\n",
       "      <td>[mochila, maternal, land, gancho, envio, gratis]</td>\n",
       "      <td>[337, 2742, 2741, 3303, 211, 1429]</td>\n",
       "      <td>318</td>\n",
       "      <td>632</td>\n",
       "      <td>63680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spanish</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Bolso Maternal Moderno Con Cambiador Y Correa ...</td>\n",
       "      <td>DIAPER_BAGS</td>\n",
       "      <td>test</td>\n",
       "      <td>[bolso, maternal, moderno, cambiador, correa, ...</td>\n",
       "      <td>[502, 2742, 2983, 2740, 1840, 476, 2990]</td>\n",
       "      <td>318</td>\n",
       "      <td>632</td>\n",
       "      <td>63680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spanish</td>\n",
       "      <td>reliable</td>\n",
       "      <td>Bolso Maternal Moderno Con Cambiador Y Correa ...</td>\n",
       "      <td>DIAPER_BAGS</td>\n",
       "      <td>test</td>\n",
       "      <td>[bolso, maternal, moderno, cambiador, correa, ...</td>\n",
       "      <td>[502, 2742, 2983, 2740, 1840, 4635]</td>\n",
       "      <td>318</td>\n",
       "      <td>632</td>\n",
       "      <td>63680</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  language label_quality                                              title  \\\n",
       "0  spanish      reliable  Mochilas Maternales Bolsos Bebe Simil Cuero Ma...   \n",
       "1  spanish      reliable  Bolso Maternal/bebe Incluye Cambiador + Correa...   \n",
       "2  spanish      reliable    Mochila Maternal Land  + Gancho Envio Gratis-cc   \n",
       "3  spanish      reliable  Bolso Maternal Moderno Con Cambiador Y Correa ...   \n",
       "4  spanish      reliable  Bolso Maternal Moderno Con Cambiador Y Correa ...   \n",
       "\n",
       "      category split                                    tokenized_title  \\\n",
       "0  DIAPER_BAGS  test  [mochilas, maternales, bolsos, bebe, simil, cu...   \n",
       "1  DIAPER_BAGS  test  [bolso, maternal, bebe, incluye, cambiador, co...   \n",
       "2  DIAPER_BAGS  test   [mochila, maternal, land, gancho, envio, gratis]   \n",
       "3  DIAPER_BAGS  test  [bolso, maternal, moderno, cambiador, correa, ...   \n",
       "4  DIAPER_BAGS  test  [bolso, maternal, moderno, cambiador, correa, ...   \n",
       "\n",
       "                                        data  target  n_labels   size  \n",
       "0  [5650, 5271, 5268, 915, 2724, 375, 37363]     318       632  63680  \n",
       "1   [502, 2742, 915, 3031, 2740, 1840, 4635]     318       632  63680  \n",
       "2         [337, 2742, 2741, 3303, 211, 1429]     318       632  63680  \n",
       "3   [502, 2742, 2983, 2740, 1840, 476, 2990]     318       632  63680  \n",
       "4        [502, 2742, 2983, 2740, 1840, 4635]     318       632  63680  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d67367",
   "metadata": {},
   "source": [
    "### Tokens y sus etiquetas\n",
    "\n",
    "Las siguientes 3 celdas de c√≥digo demuestran que la relaci√≥n entre los datos bajo las columnas `tokenized_title` y `data` est√° dada en el archivo `spanish_token_to_index` que vincula cada palabra a un √≠ndice num√©rico entero. De todos modos, esto es a modo informativo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f7cdc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 # Un √≠ndice cualquiera para extraer datos\n",
    "items = df.at[i, 'tokenized_title']\n",
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477604c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparar la salida de esta celda con la de la siguiente\n",
    "df.at[i, 'data']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bec401d",
   "metadata": {},
   "outputs": [],
   "source": [
    "nro_items = []\n",
    "for item in items:\n",
    "    id_item = tokens.loc[item][0]\n",
    "    nro_items.append(id_item)\n",
    "nro_items"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7a0f27",
   "metadata": {},
   "source": [
    "Para el presente trabajo pr√°ctico solamente interesan las columnas **title** y **category**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e2a0a0c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mochilas Maternales Bolsos Bebe Simil Cuero Ma...</td>\n",
       "      <td>DIAPER_BAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolso Maternal/bebe Incluye Cambiador + Correa...</td>\n",
       "      <td>DIAPER_BAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mochila Maternal Land  + Gancho Envio Gratis-cc</td>\n",
       "      <td>DIAPER_BAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bolso Maternal Moderno Con Cambiador Y Correa ...</td>\n",
       "      <td>DIAPER_BAGS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bolso Maternal Moderno Con Cambiador Y Correa ...</td>\n",
       "      <td>DIAPER_BAGS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title     category\n",
       "0  Mochilas Maternales Bolsos Bebe Simil Cuero Ma...  DIAPER_BAGS\n",
       "1  Bolso Maternal/bebe Incluye Cambiador + Correa...  DIAPER_BAGS\n",
       "2    Mochila Maternal Land  + Gancho Envio Gratis-cc  DIAPER_BAGS\n",
       "3  Bolso Maternal Moderno Con Cambiador Y Correa ...  DIAPER_BAGS\n",
       "4  Bolso Maternal Moderno Con Cambiador Y Correa ...  DIAPER_BAGS"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columns=['language', 'label_quality', 'split', 'tokenized_title', 'data', 'target', 'n_labels', 'size'],\n",
    "        inplace=True)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b0f8da",
   "metadata": {},
   "source": [
    "### Etiquetar el target.\n",
    "\n",
    "A cada una de las 632 categor√≠as del target se le asigna un valor entero entre 0 y 631. La relaci√≥n entre la categor√≠a u su etiqueta queda almacenada en un dataframe de Pandas llamado `df_categories`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8e079aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = df.category.unique()\n",
    "sorted_categories = np.sort(categories)\n",
    "df_categories = pd.DataFrame(sorted_categories, columns=['categories'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "29920e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_categories['cat_tag'] = pd.DataFrame(list(range(df_categories.shape[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c279da02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cat_tag</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>categories</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3D_PRINTERS</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACCORDIONS</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACOUSTIC_GUITARS</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ACTION_FIGURES</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ADHESIVE_TAPES</th>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  cat_tag\n",
       "categories               \n",
       "3D_PRINTERS             0\n",
       "ACCORDIONS              1\n",
       "ACOUSTIC_GUITARS        2\n",
       "ACTION_FIGURES          3\n",
       "ADHESIVE_TAPES          4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_categories.set_index('categories', inplace=True)\n",
    "df_categories.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1e1d327",
   "metadata": {},
   "source": [
    "## Construcci√≥n del Dataset\n",
    "\n",
    "El dataset se construye a partir de un dataframe de Pandas. El mismo debe tener al menos dos columnas:\n",
    "- **title**\n",
    "- **category**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ba04cc96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El dataset tiene 63680 elementos.\n",
      "Elemento #1000:\n",
      "\tData: Jardinero Verano Beba Nena Jean Denim H/ T 6. Regalosdemama\n",
      "\tTarget: JUMPSUITS_AND_OVERALLS\n"
     ]
    }
   ],
   "source": [
    "class MeLiChallengeDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        item = {\n",
    "            \"data\": self.df.iloc[item][\"title\"],\n",
    "            \"target\": self.df.iloc[item][\"category\"]\n",
    "        }\n",
    "\n",
    "        if self.transform:\n",
    "            item = self.transform(item)\n",
    "        \n",
    "        return item\n",
    "\n",
    "dataset = MeLiChallengeDataset(df)\n",
    "i = 1000\n",
    "print(f\"El dataset tiene {len(dataset)} elementos.\")\n",
    "print(f\"Elemento #{i}:\\n\\tData: {dataset[i]['data']}\\n\\tTarget: {dataset[i]['target']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e37e833f",
   "metadata": {},
   "source": [
    "## Preprocesamiento de los datos\n",
    "\n",
    "El preprocesamiento de texto tiene dos prop√≥sitos:\n",
    "- Tokenizar los t√≠tulos (datos) de modo que se quiten los signos de puntuaci√≥n y palabras cortas como preposiciones y conjunciones (stopwords), todas las palabras queden en min√∫sculas, se separen en listas de palabras, etc.\n",
    "- Transformar las categor√≠as en etiquetas num√©ricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b47974aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: ['jardinero', 'verano', 'beba', 'nena', 'jean', 'denim', 'regalosdemama']\n",
      "Target: 327\n"
     ]
    }
   ],
   "source": [
    "class TextPreprocess:\n",
    "    def __init__(self, df_categories, filters=None):\n",
    "        if filters:\n",
    "            self.filters = filters\n",
    "        else:\n",
    "            self.filters = [\n",
    "                lambda s: s.lower(),\n",
    "                preprocessing.strip_tags,\n",
    "                preprocessing.strip_punctuation,\n",
    "                preprocessing.strip_multiple_whitespaces,\n",
    "                preprocessing.strip_numeric,\n",
    "                preprocessing.remove_stopwords,\n",
    "                preprocessing.strip_short,\n",
    "            ]\n",
    "        self.df_categories = df_categories\n",
    "        \n",
    "    def _preprocess_string(self, string):\n",
    "        return preprocessing.preprocess_string(string, filters=self.filters)\n",
    "\n",
    "    def __call__(self, item):\n",
    "        if isinstance(item[\"data\"], str):\n",
    "            data = self._preprocess_string(item[\"data\"])\n",
    "        else:\n",
    "            data = [self._preprocess_string(d) for d in item[\"data\"]]\n",
    "        \n",
    "        category = item[\"target\"]\n",
    "        target = self.df_categories.at[category, 'cat_tag']\n",
    "        \n",
    "        return {\n",
    "            \"data\": data,\n",
    "            \"target\": target\n",
    "        }\n",
    "\n",
    "text_preprocess = TextPreprocess(df_categories)\n",
    "print(f\"Data: {text_preprocess(dataset[i])['data']}\\nTarget: {text_preprocess(dataset[i])['target']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77568602",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MeLiChallengeDataset(IterableDataset):\n",
    "\n",
    "#     def __init__(self, path, transform=None):\n",
    "#         self.dataset_path = path\n",
    "#         self.transform = transform\n",
    "\n",
    "#     def __iter__(self):\n",
    "#         with gzip.open(self.dataset_path, \"rt\") as json_file:\n",
    "#             for line in json_file:\n",
    "#                 data = json.loads(line)\n",
    "#                 item = {\n",
    "#                     \"data\": data['title'],\n",
    "#                     \"target\": data['category']\n",
    "#                 }\n",
    "#                 if self.transform:\n",
    "#                     yield self.transform(item)\n",
    "#                 else:\n",
    "#                     yield item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debcb9fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VectorizeText:\n",
    "    def __init__(self, glove_vectors_path):\n",
    "        self.glove_model = KeyedVectors.load_word2vec_format(\"../data/glove.6B.50d.txt\",\n",
    "                                                             binary=False,\n",
    "                                                             no_header=True)\n",
    "        self.unkown_vector = np.random.randn(self.glove_model.vector_size)  # Random vector for unknown words\n",
    "    \n",
    "    def _get_vector(self, word):\n",
    "        if word in self.glove_model:\n",
    "            return self.glove_model[word]\n",
    "        else:\n",
    "            return self.unkown_vector\n",
    "    \n",
    "    def _get_vectors(self, sentence):\n",
    "        return np.vstack([self._get_vector(word) for word in sentence])\n",
    "    \n",
    "    def __call__(self, item):\n",
    "        review = []\n",
    "        if isinstance(item[\"data\"][0], str):\n",
    "            review = self._get_vectors(item[\"data\"])\n",
    "        else:\n",
    "            review = [self._get_vectors(d) for d in item[\"data\"]]\n",
    "\n",
    "        return {\n",
    "            \"data\": review,\n",
    "            \"target\": item[\"target\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ddaa276",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordVectorsAverage:\n",
    "    def __call__(self, item):\n",
    "        if item[\"data\"][0].ndim == 2:\n",
    "            data = np.vstack([np.mean(d, axis=0) for d in item[\"data\"]])\n",
    "        else:\n",
    "            data = np.mean(item[\"data\"], axis=0)\n",
    "        \n",
    "        return {\n",
    "            \"data\": data,\n",
    "            \"target\": item[\"target\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbb0951",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToTensor:\n",
    "    def __call__(self, item):\n",
    "        \"\"\"\n",
    "        This espects a single array.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"data\": torch.from_numpy(item[\"data\"]),\n",
    "            \"target\": torch.tensor(item[\"target\"])\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01245c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compose(*functions):\n",
    "    return functools.reduce(lambda f, g: lambda x: g(f(x)), functions, lambda x: x)\n",
    "\n",
    "preprocess = TextPreprocess(df_categories)\n",
    "vectorizer = VectorizeText(ARCHIVO_TOKENS)\n",
    "vector_average = WordVectorsAverage()\n",
    "to_tensor = ToTensor()\n",
    "dataset = MeLiChallengeDataset(df,\n",
    "                               transform=compose(preprocess, vectorizer, vector_average, to_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46cf4600",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, sample in enumerate(dataset):\n",
    "    print(sample[\"data\"])\n",
    "    print(sample[\"target\"])\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    if idx == 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720625c",
   "metadata": {},
   "source": [
    "## Carga del Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b12ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(dataset, batch_size=4, shuffle=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80b85b12",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, \n",
    "          sample_batched['data'].size(),\n",
    "          sample_batched['target'].size())\n",
    "\n",
    "    if i_batch == 2:\n",
    "        print(sample_batched[\"data\"])\n",
    "        print(sample_batched[\"target\"])\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4f7f30",
   "metadata": {},
   "source": [
    "## Construcci√≥n del Modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27fdf2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.hidden_layer1 = torch.nn.Linear(50, 512)\n",
    "        self.hidden_layer2 = torch.nn.Linear(512, 256)\n",
    "        self.output_layer = torch.nn.Linear(256, 632)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.hidden_layer1(x)  # Go through hidden layer 1\n",
    "        x = torch.nn.functional.relu(x)  # Activation Function layer 1\n",
    "        x = self.hidden_layer2(x) # Go through hidden layer 2\n",
    "        x = torch.nn.functional.relu(x)  # Activation Function layer 2\n",
    "        x = self.output_layer(x)  # Output Layer\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "274fe854",
   "metadata": {},
   "source": [
    "## Algoritmo de Optimizaci√≥n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a15de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "loss_function = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c7772d8",
   "metadata": {},
   "source": [
    "## Entrenamiento del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6140ff3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "model.train()  # Tell the model to set itself to \"train\" mode.\n",
    "for epoch in range(EPOCHS):  # loop over the dataset multiple times\n",
    "    running_loss = 0.0\n",
    "    # pbar = tqdm(dataloader)\n",
    "    for i, data in enumerate(dataloader):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        # inputs: tensor de Torch de dimensi√≥n [BATCH_SIZE, 3, 32, 32]\n",
    "        # labels: tensor de Torch de dimensi√≥n [BATCH_SIZE]\n",
    "        inputs = data[\"data\"]\n",
    "        labels = data[\"target\"]\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs) # Al modelo le ingreso como argumento un\n",
    "                                                          # tensor de Torch de dimensi√≥n [BATCH_SIZE, 3072]\n",
    "        loss = loss_function(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "        if i > 0 and i % 50 == 0:    # print every 50 mini-batches\n",
    "            pbar.set_description(f\"[{epoch + 1}, {i}] loss: {running_loss / 50:.4g}\")\n",
    "            running_loss = 0.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f378dee4",
   "metadata": {},
   "source": [
    "## Evaluaci√≥n del Modelo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e169eaaa",
   "metadata": {},
   "source": [
    "## Guardado de los par√°metros del modelo"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
